{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adverserial Network for Fake Image Generation\n",
    "\n",
    "In this Notebook, we will train an FC-GAN to genereate fake Mnist data.\n",
    "\n",
    "Followed by a conversion of the FC-GAN to DC-GAN, and the generation of higher resolution images.\n",
    "\n",
    "Gan Paper: https://arxiv.org/abs/1406.2661\n",
    "\n",
    "PyTorch MNist dataset : https://pytorch.org/docs/stable/torchvision/datasets.html#mnist\n",
    "\n",
    "Convert FC-Gan To DC-Gan Paper : https://arxiv.org/pdf/1511.06434.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC-GAN for the Generation of Fake MNIST Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frist load the MNist dataset from pytorch\n",
    "\n",
    "def load_mnist_minibatched(batch_size: int, n_train: int = 8192, n_valid: int = 1024,\n",
    "                           valid_test_batch_size: int = 1024) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='../data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='../data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(range(n_train))\n",
    "    validation_sampler = SubsetRandomSampler(range(n_train, n_train+n_valid))\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    validation_loader = DataLoader(dataset=train_dataset, batch_size=valid_test_batch_size,\n",
    "                                   sampler=validation_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=valid_test_batch_size, \n",
    "                                              shuffle=False)\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what the MNist data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB5CAYAAAAtfwoEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAATZklEQVR4nO3de7BU1ZXH8e8S8IGWvCSEVxQVMUh8xBsfkaCFGohGMYllNBnHqSFF/siUZmqqRjP5Y8r5K1MzpTNTMxPLSjLiaHyAGYMxqIAag4kgvoCACIoi5CIaX4gGRdb80eds1pVuum/f7nvvOfw+VRSrT7/26dNsdq+zz9rm7oiISHkc0NcNEBGR1lLHLiJSMurYRURKRh27iEjJqGMXESkZdewiIiXTo47dzGaa2Toz22Bm17WqUSIi0jxrdh67mQ0AXgDOBzYDTwJXuPua1jVPRES6a2APnnsasMHdXwIwszuBWUDNjn3w4ME+dOjQHryliMj+p7Oz8w13H9no43vSsY8FXg23NwOnf/JBZjYHmAMwZMgQ5syZ04O3FBHZ/1x//fWvdOfxbT956u43u3uHu3cMHjy43W8nIrLf60nHvgUYH26Py7aJiEgf6knH/iQw0cwmmNmBwOXAgtY0S0REmtV0jt3dd5nZ3wAPAgOAn7n7H1rWMhERaUpPTp7i7r8Gft2itoiISAvoylMRkZJRxy4iUjLq2EVESkYdu4hIyahjFxEpGXXsIiIlo45dRKRk1LGLiJSMOnYRkZLp0ZWnRRQrTJ566qkADBgwIG07++yzU2xmKc4XJFm6dGna9vvf/z7F77//fusbKyLSBI3YRURKRh27iEjJlC4VM2zYMAAmTpyYtp1yyikpHj58eIoHDRq01/NrrQGbbz/rrLPStgkTJqT4zjvvTPF7773X3WZLN4wYMQKA448/vur9jz/+eG82Rwri4IMPTnFHR0eKjzzyyL3i2DfENGv8bv3ud79rSztbQSN2EZGSUccuIlIypUjFxPTKFVdcAez5ud5OY8aMSfFll12W4nnz5gGwffv2trehyKZNm5biNWvWAHDMMcekbcuWLUvxQQcdlOKvfe1rAIwdO7bq65YtFXPCCSekeMqUKUDXz+Pwww9Pcdy+du1aALZt25a2rV69OsV//vOfW9/Yfmjy5MkAXHjhhWlbrfWXd+zYAcArr+xZOzqmas4999y9Hvvcc8+1rrEtohG7iEjJqGMXESmZUqRixo8fn+KepmBef/31FFe7QGnkyJFVnzdu3LgUf/aznwVg+fLlPWpL0Q0dOhTomjKJP4cPPPDAFH/xi18E4MUXX0zb4k/cK6+8MsUxBVZW8Tt98cUXpzj/zD744IO0rbOzM8XxOztp0iQAvvCFL6RtJ598copvu+22FJctLRPTU5dccgnQ9ULEZ555JsUrV65M8csvv7zXa+XfY4BrrrkmxfkMuUKmYszsZ2a2zcxWh23DzWyRma3P/h7W3maKiEijGhmx3wL8J3Br2HYdsMTdf2Rm12W3r21981rvo48+SvFDDz0EwNatW9O2d999d5/P/+53v5viWidgPve5zwH754g9js6//vWvA11PbteSj6ZGjRqVtsW5xnEEVlbHHXdcii+99NIUx1H4ww8/DHT9bu3cubPq6+VzseOI/fzzz09x/j0FePLJJ5ttdr80evToFOefQywHsmTJkn0+/6ijjkrxRRddVPUxtf799wd1R+zu/hjw5ic2zwLmZvFc4JIWt0tERJrU7MnTUe6eJ/a2AqNqPdDM5pjZCjNboUJZIiLt1+OTp+7uZlb9OvzK/TcDNwOMGTOm5uN6Iv6HsWvXLgA+/vjjtO2ll15KcazIuHnz5obfI798Pc4T3p/Fz2HGjBkpjqmYRlIwuYULFwJd02LxRN9hhx3WVDuLIC9/Ea+FePvtt1N87733prg739k87bhq1aq0berUqSk+4ogjut/YgognPHObNm2q+th4UvWkk04Cus5XjymX3bt3p3jRokU9bme7NDtif83MRgNkf2+r83gREeklzXbsC4Crsvgq4JetaY6IiPRU3VSMmd0BnAMcYWabgX8EfgTcbWazgVeAy2q/QvutX78+xXmVxTj75dVXX23qdfNLkQG+9KUvAV1/ttUSf/qWwcCBe74m+U/UOIOjXsol/nyN86UXL16c4nwucHxsTMXUM3/+/IYf2x/Ez+wb3/gG0HXf77///hR3J/0S5fOsTz/99LTtkEMOaeq1yiCWBvjjH/+Y4i9/+cspPvHEE/d63ooVK1L8wgsvpDj2O/1N3Y7d3a+ocde5NbaLiEgfUkkBEZGSKUVJgSjOgGlUnHFx3nnnpfhTn/pUiuOFM9XEUgR5pcIii7Nepk+fnuLTTjut4dfIK+TFVEJMv/RUrFr42muvtex12+WAA/aMo2bNmpXifAGIuXPnpm0bN25s+HXj9zdPGUL9Y9Wd9yiamGrJxQV3YgmQmKLJZ9jlFVqhepmB/k4jdhGRkindiL2aOFKK81vzk0rxf+w4Sq9WBKyWOMLNR1CxUFOcV99fxZOVn/nMZ1IcRzr1xJNL+QnAemUaojgPvla99VwsvvTGG280/B59JRaoi59vXoSqOyPDuCxjvI6g3i/LOD++mV+3RRFH7Pk+x3/78d/8O++8k+J77rkHaH7CRX+hEbuISMmoYxcRKZn9IhUTK73Nnj27Le8Rqw/OmTMHgKeeeipti/OS+5t87m6cz9ud+c5xGbG4n91JweRiKiGmxaq9X1zmrQhixcDo2WefBWqn++LnkNdmj+UAulPm4r777kvxhx9+2PDziiamXfIa9jG1WqtkQ9FTMDmN2EVESkYdu4hIyewXqZhYqS3+HKunO4+tJi4UEUsRLFiwoEev2wpx8YULLrig4ee9+WalNP+tt+5ZdyXOKmjWtddW1mnJ53RD7VlJeVmCZlI9fanWghj5fPO48EWsKHjMMcekuJGSFp8Ur7Eo80yYKC6lmH+W8TsUP98izlOvRyN2EZGSUccuIlIy+0Uq5tFHH01xtZkJ8eKhp59+OsX5+pK1jBw5MsXf/OY3U3zooYfu9dh8oQ6AZcuWpbivLoXvTvoltjFPI7Ui/RJVmxESt8VqnWvXrm3pe/eWLVu2pDh+ppMmTWr4NfJUWCOLmOSLztx9990Nv36R5TOGAIYMGZLifBZVvGjpzDPPTHFMS5Zl7VeN2EVESma/GLHHkdKNN964z8du37694deNxa1uuummFOdLnI0fPz5tiycFv/WtbzXcnr4ST0zGeb5x6bqemjZtWorzuca1xBF7LCVQJH/6059SHEfR+a+neGL0+eefrxrnj7n66qvTtvjLJv76vOOOO4BilFtoViw7EWupx+9L/isznoyPI/ZY3kEjdhER6ZfUsYuIlMx+kYqJP0+7k2ppVr1LvOulHfqDeLl5T9MvsfZ1TEPFz6Ha/Ox4rG6//fYetaG/yU+CAtx2220NPy8vJVCr/MAjjzyS4v1hznqschm/Q0888USK8886TmqI360pU6akOP/84vEporojdjMbb2aPmNkaM/uDmV2TbR9uZovMbH3297D2N1dEROppJBWzC/g7d58MnAF8z8wmA9cBS9x9IrAkuy0iIn2skcWsO4HOLN5uZmuBscAs4JzsYXOBR4Fr29LKfirOejnnnHNSXK0qYUwH1Zsf3xvighjHHXfcXvfHWTxxUYJYybGaOEshr9Q4bNieH3P1qkbGmSOx9EIRlr5rl5jai9dL5GJFwngdRpnlM1xOPfXUqvdXW55yx44dKY7XQsQlBPPrXEqfionM7CjgFGAZMCrr9AG2AlWXbjGzOWa2wsxW5OsJiohI+zTcsZvZYcA9wPfdvUv1Ja+cyal6Nsfdb3b3DnfviIV3RESkPRqaFWNmg6h06re7+y+yza+Z2Wh37zSz0cC22q9QfGPGjAG6rgJ/9NFHp3jQoEF7PSe/pBtg8eLFKe4PF0E8/vjjKa6WisnXbQW46KKLUrxp06Z9vm5MxeQpqUbWjl24cCHQdQZOvfcqs1rpl3xWzFtvvZW2/fznP09xXvmy7PJ/j3FBjcceeyzFsXxANfECpqjav+MiamRWjAE/Bda6+w3hrgXAVVl8FfDL1jdPRES6q5ER+1nAlcAqM3s22/YPwI+Au81sNvAKcFl7mlhdXBps6tSpKc5HOnFU3Ozc9enTp6d44sSJABxwQP3sVT5Sj6P05cuXN9WGduns7Ezxb37zG6Dr5xjnBI8YMaJq3KhaxbzyUTrsKROwe/fubr9+GcXvXpyrnbvrrrtSvL+M0qNqad3unMOLNerLqJFZMUuBWitOnFtju4iI9BGVFBARKZnClhT4zne+k+Jql+h3p8Z1LY2c9MvFeep5Cqa/pV+imBLJ69XHfTj77LNT3MxybNEHH3yQ4gcffDDFRa3S2C5xTnacWx2/e3kKZn+e19+s+D2OZQRi+q/o89dzGrGLiJSMOnYRkZIpbComVh+MM1UGDmzvLsX33bZtz9T9OC983bp1bW1Du/z2t79N8c6dO1Pc0880zkpatWpVj16rjD796U8DXZcrjOmBefPmpbio361Wi+UBcvUugIyLaxx77LEpjp/p+vXrW9C6vqcRu4hIyahjFxEpmcKmYm64Yc9FsHkVQdhzIVFHR0fadvjhhzf1HkuWLNlrW5zpEtMyZdOfZ/SUQayeOWvWrL3uj+mXuOapVOQX2MVqo3EN3ZhqGTlyJNC1XEC8QOm+++5rWzv7ikbsIiIlU9gRexTn9Obx0qVL+6o5IlXFk9CxsFd+8nTjxo1pm0bp+5bP7X/ggQfStpkzZ6a42hoCK1euTNtivfYylmTQiF1EpGTUsYuIlEwpUjEiRTBjxowU50uwwZ704fz583u7SYUX6/ffcsstfdeQfkYjdhGRklHHLiJSMkrFiPSS+++/v2os0moasYuIlIw6dhGRklHHLiJSMnU7djM72MyWm9lzZvYHM7s+2z7BzJaZ2QYzu8vM9l7GSEREel0jI/adwHR3Pwk4GZhpZmcA/wzc6O7HAm8Bs9vXTBERaVTdjt0r3stuDsr+ODAdyK+omAtc0pYWiohItzSUYzezAWb2LLANWAS8CLzt7ruyh2wGxtZ47hwzW2FmK95///1WtFlERPahoY7d3T9295OBccBpwPGNvoG73+zuHe7eUW/pKhER6bluzYpx97eBR4AzgaFmll/gNA7Y0uK2iYhIExqZFTPSzIZm8SHA+cBaKh38pdnDrgJ+2a5GiohI4ywvWF/zAWYnUjk5OoDKfwR3u/s/mdnRwJ3AcOAZ4C/cfWftVwIzex3YAbzRgrb3R0egfSsi7Vsx7U/7dqS7j2z0yXU79lYzsxXu3lH/kcWjfSsm7Vsxad9q05WnIiIlo45dRKRk+qJjv7kP3rO3aN+KSftWTNq3Gno9xy4iIu2lVIyISMmoYxcRKZle7djNbKaZrctK/V7Xm+/damY23sweMbM1WTnja7Ltw81skZmtz/4e1tdtbUZWH+gZM/tVdrsUZZrNbKiZzTez581srZmdWaJj9rfZd3G1md2Rldwu5HEzs5+Z2TYzWx22VT1OVvEf2T6uNLPP913L66uxb/+SfSdXmtn/5ReFZvf9INu3dWY2o5H36LWO3cwGAP8FfAWYDFxhZpN76/3bYBfwd+4+GTgD+F62P9cBS9x9IrAku11E11C5wjhXljLN/w484O7HAydR2cfCHzMzGwtcDXS4+xQqFxReTnGP2y3AzE9sq3WcvgJMzP7MAX7cS21s1i3svW+LgCnufiLwAvADgKxPuRw4IXvOf2d96T715oj9NGCDu7/k7h9SuWp1Vi++f0u5e6e7P53F26l0EGOp7NPc7GGFLGdsZuOAC4GfZLeNEpRpNrMhwDTgpwDu/mFW/6jwxywzEDgkq+E0GOikoMfN3R8D3vzE5lrHaRZwa1Zi/AkqdaxG905Lu6/avrn7Q6Fa7hNU6m9BZd/udPed7r4R2EClL92n3uzYxwKvhts1S/0WjZkdBZwCLANGuXtndtdWYFQfNasn/g34e2B3dnsEDZZp7ucmAK8D/5OlmX5iZodSgmPm7luAfwU2UenQ3wGeohzHLVfrOJWtb/lrYGEWN7VvOnnaQ2Z2GHAP8H13fzfe55W5pIWaT2pmXwW2uftTfd2WNhgIfB74sbufQqVuUZe0SxGPGUCWb55F5T+vMcCh7P1zvzSKepzqMbMfUknz3t6T1+nNjn0LMD7cLnypXzMbRKVTv93df5Ftfi3/GZj9va2v2teks4CLzexlKumy6VTy0mUo07wZ2Ozuy7Lb86l09EU/ZgDnARvd/XV3/wj4BZVjWYbjlqt1nErRt5jZXwFfBb7tey4wamrferNjfxKYmJ2lP5DKCYEFvfj+LZXlnX8KrHX3G8JdC6iUMYYCljN29x+4+zh3P4rKMXrY3b9NCco0u/tW4FUzm5RtOhdYQ8GPWWYTcIaZDc6+m/m+Ff64BbWO0wLgL7PZMWcA74SUTSGY2Uwq6c+L3T0uNbcAuNzMDjKzCVROEC+v+4Lu3mt/gAuonPF9Efhhb753G/ZlKpWfgiuBZ7M/F1DJRy8B1gOLgeF93dYe7OM5wK+y+OjsC7UBmAcc1Nfta3KfTgZWZMftXmBYWY4ZcD3wPLAa+F/goKIeN+AOKucKPqLyS2t2reMEGJUZdy8Cq6jMDOrzfejmvm2gkkvP+5KbwuN/mO3bOuArjbyHSgqIiJSMTp6KiJSMOnYRkZJRxy4iUjLq2EVESkYdu4hIyahjFxEpGXXsIiIl8//uHfBh2qJ/5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3     0     9     8\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "trainloader, validation_loader, test_loader = load_mnist_minibatched(batch_size)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "img = torchvision.utils.make_grid(images[:4,:,:,:])\n",
    "\n",
    "# show images\n",
    "img = img / 2 + 0.5     # unnormalize\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The adverserial Networks:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Generative Network:\n",
    "\n",
    "Input: x values sampled from uniform distribution\n",
    "\n",
    "Output: 32 x 32 Image, that should look like the data from MNist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generativeNet(\n",
       "  (fc1): Linear(in_features=10, out_features=36, bias=True)\n",
       "  (fc2): Linear(in_features=36, out_features=144, bias=True)\n",
       "  (fc3): Linear(in_features=144, out_features=576, bias=True)\n",
       "  (fc4): Linear(in_features=576, out_features=784, bias=True)\n",
       "  (ReLU): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Generative Network\n",
    "\n",
    "class generativeNet(nn.Module):\n",
    "    \"\"\"\n",
    "        The CNN convolutional network with architecture defined above\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 10, out_features=6 * 6)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features= 6 * 6, out_features=12 * 12)\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features= 12 * 12, out_features=24 * 24)\n",
    "        \n",
    "        self.fc4 = nn.Linear(in_features= 24 * 24, out_features=28 * 28)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            x: The input tensor with shape [batch_size, feature_dim] (minibatch of data)\n",
    "        Returns:\n",
    "            scores: Pytorch tensor of shape (N, C) giving classification scores for x\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc4(x)        \n",
    "        return x\n",
    "    \n",
    "G = generativeNet()\n",
    "G.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The discriminative network:\n",
    "\n",
    "Input: Takes 32 x 32 Image as Input\n",
    "Output: probability of it being real data (non generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discrimNet(\n",
       "  (fc1): Linear(in_features=784, out_features=484, bias=True)\n",
       "  (fc2): Linear(in_features=484, out_features=144, bias=True)\n",
       "  (fc3): Linear(in_features=144, out_features=36, bias=True)\n",
       "  (fc4): Linear(in_features=36, out_features=2, bias=True)\n",
       "  (ReLU): ReLU()\n",
       "  (soft): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class discrimNet(nn.Module):\n",
    "    \"\"\"\n",
    "        The CNN convolutional network with architecture defined above\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 28 * 28, out_features=22 * 22)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features= 22 * 22, out_features=12 * 12)\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features= 12 * 12, out_features=6 * 6)\n",
    "        \n",
    "        # 2 class fake and real data\n",
    "        self.fc4 = nn.Linear(in_features= 6 * 6, out_features=2)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: The input tensor with shape [batch_size, feature_dim] (minibatch of data)\n",
    "        Returns:\n",
    "            scores: Pytorch tensor of shape (N, C) giving classification scores for x\n",
    "        \"\"\"\n",
    "        \n",
    "        x = x.view(x.shape[0], 28 * 28)\n",
    "    \n",
    "        x = self.fc1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc4(x)        \n",
    "        return self.soft(x)\n",
    "\n",
    "D = discrimNet()\n",
    "D.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The Noise Prior for the Generative Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58794429 0.20233576 0.79698566 0.71181937 0.36205579 0.59251127\n",
      " 0.2892727  0.82244205 0.13243784 0.78482592]\n"
     ]
    }
   ],
   "source": [
    "# Define The Noise Distribution, we us the Gaussian Nosie Distribution:\n",
    "\n",
    "# always use the same seed to get the same random variables\n",
    "# np.random.seed(0)\n",
    "\n",
    "# Here is how to sample a vector of 10 values from uniform distribution\n",
    "s = np.random.uniform(0,1, 10)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define new loss function for both networks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef lossRealData(outputs):\\n    \\n    labels = torch.ones(outputs.shape).cuda()\\n    criterion = nn.BCELoss()\\n    loss = criterion(outputs, labels)\\n    return loss\\n    \\ndef lossFakeData(outputs):\\n    ones = torch.ones(outputs.shape).cuda()\\n    labels = torch.zeros(outputs.shape).cuda()\\n    outputs = torch.abs(ones - outputs)\\n    cirterion = nn.BCELoss()\\n    loss = cirterion(outputs,labels)\\n    return loss\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define the loss function for the Discriminator Network:\n",
    "\n",
    "\"\"\"\n",
    "def lossRealData(outputs):\n",
    "    \n",
    "    labels = torch.ones(outputs.shape).cuda()\n",
    "    criterion = nn.BCELoss()\n",
    "    loss = criterion(outputs, labels)\n",
    "    return loss\n",
    "    \n",
    "def lossFakeData(outputs):\n",
    "    ones = torch.ones(outputs.shape).cuda()\n",
    "    labels = torch.zeros(outputs.shape).cuda()\n",
    "    outputs = torch.abs(ones - outputs)\n",
    "    cirterion = nn.BCELoss()\n",
    "    loss = cirterion(outputs,labels)\n",
    "    return loss\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for sampling the noise data\n",
    "\n",
    "def sample_noise(batch_size=batch_size):\n",
    "    noise_batch = []\n",
    "    for i in range(batch_size):\n",
    "        s = np.random.uniform(0,1, 10) # 10 values sample from uniform distribution\n",
    "        noise_batch.append(s)\n",
    "\n",
    "    noise_batch = torch.from_numpy(np.asarray(noise_batch)).float() \n",
    "    return noise_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability(device=None)\n",
    "torch.cuda.get_device_name(device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the real labels\n",
    "a_real = []\n",
    "a_fake = []\n",
    "for i in range(batch_size):\n",
    "    sub1 = [1]\n",
    "    sub2 = [0]\n",
    "    for j in range(1):\n",
    "        sub1.append(0)\n",
    "        sub2.append(1)\n",
    "    a_real.append(sub1)\n",
    "    a_fake.append(sub2)\n",
    "\n",
    "labels_real = torch.tensor(a_real, dtype=torch.float).cuda()\n",
    "labels_fake = torch.tensor(a_fake, dtype=torch.float).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running epoch Nbr 0\n",
      "\t[1,   100] D loss: 0.000037751\n",
      "\t[1,   200] D loss: 0.000042724\n",
      "\t[2,   100] D loss: 0.000040527\n",
      "\t[2,   200] D loss: 0.000041352\n",
      "\t[3,   100] D loss: 0.000038777\n",
      "\t[3,   200] D loss: 0.000042515\n",
      "\t\t Running 0th iteration on G\n",
      "\t\t G Loss is : 0.000032329\n",
      "Currently running epoch Nbr 1\n",
      "\t[1,   100] D loss: 0.000036162\n",
      "\t[1,   200] D loss: 0.000044478\n",
      "\t[2,   100] D loss: 0.000040552\n",
      "\t[2,   200] D loss: 0.000039435\n",
      "\t[3,   100] D loss: 0.000037328\n",
      "\t[3,   200] D loss: 0.000040958\n",
      "\t\t Running 1th iteration on G\n",
      "\t\t G Loss is : 0.000031757\n",
      "Currently running epoch Nbr 2\n",
      "\t[1,   100] D loss: 0.000037318\n",
      "\t[1,   200] D loss: 0.000038580\n",
      "\t[2,   100] D loss: 0.000038384\n",
      "\t[2,   200] D loss: 0.000039702\n",
      "\t[3,   100] D loss: 0.000040081\n",
      "\t[3,   200] D loss: 0.000039515\n",
      "\t\t Running 2th iteration on G\n",
      "\t\t G Loss is : 0.000030719\n",
      "Currently running epoch Nbr 3\n",
      "\t[1,   100] D loss: 0.000036106\n",
      "\t[1,   200] D loss: 0.000039026\n",
      "\t[2,   100] D loss: 0.000036617\n",
      "\t[2,   200] D loss: 0.000036652\n",
      "\t[3,   100] D loss: 0.000039552\n",
      "\t[3,   200] D loss: 0.000035850\n",
      "\t\t Running 3th iteration on G\n",
      "\t\t G Loss is : 0.000030387\n",
      "Currently running epoch Nbr 4\n",
      "\t[1,   100] D loss: 0.000039032\n",
      "\t[1,   200] D loss: 0.000037326\n",
      "\t[2,   100] D loss: 0.000035852\n",
      "\t[2,   200] D loss: 0.000036327\n",
      "\t[3,   100] D loss: 0.000037853\n",
      "\t[3,   200] D loss: 0.000038277\n",
      "\t\t Running 4th iteration on G\n",
      "\t\t G Loss is : 0.000029582\n",
      "Currently running epoch Nbr 5\n",
      "\t[1,   100] D loss: 0.000035216\n",
      "\t[1,   200] D loss: 0.000040249\n",
      "\t[2,   100] D loss: 0.000037931\n",
      "\t[2,   200] D loss: 0.000036500\n",
      "\t[3,   100] D loss: 0.000035765\n",
      "\t[3,   200] D loss: 0.000038327\n",
      "\t\t Running 5th iteration on G\n",
      "\t\t G Loss is : 0.000029530\n",
      "Currently running epoch Nbr 6\n",
      "\t[1,   100] D loss: 0.000035130\n",
      "\t[1,   200] D loss: 0.000036502\n",
      "\t[2,   100] D loss: 0.000037046\n",
      "\t[2,   200] D loss: 0.000036340\n",
      "\t[3,   100] D loss: 0.000037514\n",
      "\t[3,   200] D loss: 0.000035978\n",
      "\t\t Running 6th iteration on G\n",
      "\t\t G Loss is : 0.000028484\n",
      "Currently running epoch Nbr 7\n",
      "\t[1,   100] D loss: 0.000034736\n",
      "\t[1,   200] D loss: 0.000036171\n",
      "\t[2,   100] D loss: 0.000031909\n",
      "\t[2,   200] D loss: 0.000037706\n",
      "\t[3,   100] D loss: 0.000034889\n",
      "\t[3,   200] D loss: 0.000036354\n",
      "\t\t Running 7th iteration on G\n",
      "\t\t G Loss is : 0.000027950\n",
      "Currently running epoch Nbr 8\n",
      "\t[1,   100] D loss: 0.000038496\n",
      "\t[1,   200] D loss: 0.000033067\n",
      "\t[2,   100] D loss: 0.000037247\n",
      "\t[2,   200] D loss: 0.000034141\n",
      "\t[3,   100] D loss: 0.000034898\n",
      "\t[3,   200] D loss: 0.000035725\n",
      "\t\t Running 8th iteration on G\n",
      "\t\t G Loss is : 0.000028322\n",
      "Currently running epoch Nbr 9\n",
      "\t[1,   100] D loss: 0.000030238\n",
      "\t[1,   200] D loss: 0.000036057\n",
      "\t[2,   100] D loss: 0.000034553\n",
      "\t[2,   200] D loss: 0.000034298\n",
      "\t[3,   100] D loss: 0.000034395\n",
      "\t[3,   200] D loss: 0.000034798\n",
      "\t\t Running 9th iteration on G\n",
      "\t\t G Loss is : 0.000027130\n",
      "Currently running epoch Nbr 10\n",
      "\t[1,   100] D loss: 0.000033962\n",
      "\t[1,   200] D loss: 0.000034572\n",
      "\t[2,   100] D loss: 0.000035030\n",
      "\t[2,   200] D loss: 0.000032933\n",
      "\t[3,   100] D loss: 0.000030971\n",
      "\t[3,   200] D loss: 0.000033274\n",
      "\t\t Running 10th iteration on G\n",
      "\t\t G Loss is : 0.000027257\n",
      "Currently running epoch Nbr 11\n",
      "\t[1,   100] D loss: 0.000032960\n",
      "\t[1,   200] D loss: 0.000034266\n",
      "\t[2,   100] D loss: 0.000034386\n",
      "\t[2,   200] D loss: 0.000032053\n",
      "\t[3,   100] D loss: 0.000037160\n",
      "\t[3,   200] D loss: 0.000031233\n",
      "\t\t Running 11th iteration on G\n",
      "\t\t G Loss is : 0.000025919\n",
      "Currently running epoch Nbr 12\n",
      "\t[1,   100] D loss: 0.000034399\n",
      "\t[1,   200] D loss: 0.000032489\n",
      "\t[2,   100] D loss: 0.000030308\n",
      "\t[2,   200] D loss: 0.000033968\n",
      "\t[3,   100] D loss: 0.000033289\n",
      "\t[3,   200] D loss: 0.000031291\n",
      "\t\t Running 12th iteration on G\n",
      "\t\t G Loss is : 0.000025926\n",
      "Currently running epoch Nbr 13\n",
      "\t[1,   100] D loss: 0.000035298\n",
      "\t[1,   200] D loss: 0.000030463\n",
      "\t[2,   100] D loss: 0.000029735\n",
      "\t[2,   200] D loss: 0.000035267\n",
      "\t[3,   100] D loss: 0.000031167\n",
      "\t[3,   200] D loss: 0.000033986\n",
      "\t\t Running 13th iteration on G\n",
      "\t\t G Loss is : 0.000025715\n",
      "Currently running epoch Nbr 14\n",
      "\t[1,   100] D loss: 0.000029592\n",
      "\t[1,   200] D loss: 0.000035249\n",
      "\t[2,   100] D loss: 0.000033469\n",
      "\t[2,   200] D loss: 0.000031681\n",
      "\t[3,   100] D loss: 0.000031598\n",
      "\t[3,   200] D loss: 0.000031852\n",
      "\t\t Running 14th iteration on G\n",
      "\t\t G Loss is : 0.000025243\n",
      "Currently running epoch Nbr 15\n",
      "\t[1,   100] D loss: 0.000034314\n",
      "\t[1,   200] D loss: 0.000030071\n",
      "\t[2,   100] D loss: 0.000030084\n",
      "\t[2,   200] D loss: 0.000033079\n",
      "\t[3,   100] D loss: 0.000032481\n",
      "\t[3,   200] D loss: 0.000030739\n",
      "\t\t Running 15th iteration on G\n",
      "\t\t G Loss is : 0.000024795\n",
      "Currently running epoch Nbr 16\n",
      "\t[1,   100] D loss: 0.000034195\n",
      "\t[1,   200] D loss: 0.000028931\n",
      "\t[2,   100] D loss: 0.000032317\n",
      "\t[2,   200] D loss: 0.000030095\n",
      "\t[3,   100] D loss: 0.000032784\n",
      "\t[3,   200] D loss: 0.000028859\n",
      "\t\t Running 16th iteration on G\n",
      "\t\t G Loss is : 0.000024787\n",
      "Currently running epoch Nbr 17\n",
      "\t[1,   100] D loss: 0.000032193\n",
      "\t[1,   200] D loss: 0.000028664\n",
      "\t[2,   100] D loss: 0.000032810\n",
      "\t[2,   200] D loss: 0.000028695\n",
      "\t[3,   100] D loss: 0.000028824\n",
      "\t[3,   200] D loss: 0.000031874\n",
      "\t\t Running 17th iteration on G\n",
      "\t\t G Loss is : 0.000024067\n",
      "Currently running epoch Nbr 18\n",
      "\t[1,   100] D loss: 0.000032558\n",
      "\t[1,   200] D loss: 0.000027381\n",
      "\t[2,   100] D loss: 0.000027261\n",
      "\t[2,   200] D loss: 0.000029840\n",
      "\t[3,   100] D loss: 0.000031017\n",
      "\t[3,   200] D loss: 0.000028530\n",
      "\t\t Running 18th iteration on G\n",
      "\t\t G Loss is : 0.000023688\n",
      "Currently running epoch Nbr 19\n",
      "\t[1,   100] D loss: 0.000028810\n",
      "\t[1,   200] D loss: 0.000030066\n",
      "\t[2,   100] D loss: 0.000028048\n",
      "\t[2,   200] D loss: 0.000031062\n",
      "\t[3,   100] D loss: 0.000029745\n",
      "\t[3,   200] D loss: 0.000027063\n",
      "\t\t Running 19th iteration on G\n",
      "\t\t G Loss is : 0.000023450\n",
      "Currently running epoch Nbr 20\n",
      "\t[1,   100] D loss: 0.000030748\n",
      "\t[1,   200] D loss: 0.000028217\n",
      "\t[2,   100] D loss: 0.000029221\n",
      "\t[2,   200] D loss: 0.000026775\n",
      "\t[3,   100] D loss: 0.000027506\n",
      "\t[3,   200] D loss: 0.000029434\n",
      "\t\t Running 20th iteration on G\n",
      "\t\t G Loss is : 0.000022963\n",
      "Currently running epoch Nbr 21\n",
      "\t[1,   100] D loss: 0.000032637\n",
      "\t[1,   200] D loss: 0.000025909\n",
      "\t[2,   100] D loss: 0.000030453\n",
      "\t[2,   200] D loss: 0.000026547\n",
      "\t[3,   100] D loss: 0.000027693\n",
      "\t[3,   200] D loss: 0.000030113\n",
      "\t\t Running 21th iteration on G\n",
      "\t\t G Loss is : 0.000022308\n",
      "Currently running epoch Nbr 22\n",
      "\t[1,   100] D loss: 0.000027871\n",
      "\t[1,   200] D loss: 0.000029378\n",
      "\t[2,   100] D loss: 0.000027332\n",
      "\t[2,   200] D loss: 0.000027366\n",
      "\t[3,   100] D loss: 0.000030244\n",
      "\t[3,   200] D loss: 0.000026964\n",
      "\t\t Running 22th iteration on G\n",
      "\t\t G Loss is : 0.000022624\n",
      "Currently running epoch Nbr 23\n",
      "\t[1,   100] D loss: 0.000028830\n",
      "\t[1,   200] D loss: 0.000026686\n",
      "\t[2,   100] D loss: 0.000028022\n",
      "\t[2,   200] D loss: 0.000027278\n",
      "\t[3,   100] D loss: 0.000029813\n",
      "\t[3,   200] D loss: 0.000026858\n",
      "\t\t Running 23th iteration on G\n",
      "\t\t G Loss is : 0.000022142\n",
      "Currently running epoch Nbr 24\n",
      "\t[1,   100] D loss: 0.000026141\n",
      "\t[1,   200] D loss: 0.000027167\n",
      "\t[2,   100] D loss: 0.000025590\n",
      "\t[2,   200] D loss: 0.000027429\n",
      "\t[3,   100] D loss: 0.000025482\n",
      "\t[3,   200] D loss: 0.000029016\n",
      "\t\t Running 24th iteration on G\n",
      "\t\t G Loss is : 0.000021819\n",
      "Currently running epoch Nbr 25\n",
      "\t[1,   100] D loss: 0.000024884\n",
      "\t[1,   200] D loss: 0.000026866\n",
      "\t[2,   100] D loss: 0.000028337\n",
      "\t[2,   200] D loss: 0.000027314\n",
      "\t[3,   100] D loss: 0.000029757\n",
      "\t[3,   200] D loss: 0.000024825\n",
      "\t\t Running 25th iteration on G\n",
      "\t\t G Loss is : 0.000021137\n",
      "Currently running epoch Nbr 26\n",
      "\t[1,   100] D loss: 0.000027066\n",
      "\t[1,   200] D loss: 0.000026839\n",
      "\t[2,   100] D loss: 0.000028760\n",
      "\t[2,   200] D loss: 0.000024895\n",
      "\t[3,   100] D loss: 0.000024488\n",
      "\t[3,   200] D loss: 0.000026674\n",
      "\t\t Running 26th iteration on G\n",
      "\t\t G Loss is : 0.000021124\n",
      "Currently running epoch Nbr 27\n",
      "\t[1,   100] D loss: 0.000026704\n",
      "\t[1,   200] D loss: 0.000025743\n",
      "\t[2,   100] D loss: 0.000028551\n",
      "\t[2,   200] D loss: 0.000022938\n",
      "\t[3,   100] D loss: 0.000028722\n",
      "\t[3,   200] D loss: 0.000024132\n",
      "\t\t Running 27th iteration on G\n",
      "\t\t G Loss is : 0.000020513\n",
      "Currently running epoch Nbr 28\n",
      "\t[1,   100] D loss: 0.000024897\n",
      "\t[1,   200] D loss: 0.000024364\n",
      "\t[2,   100] D loss: 0.000025277\n",
      "\t[2,   200] D loss: 0.000025250\n",
      "\t[3,   100] D loss: 0.000025166\n",
      "\t[3,   200] D loss: 0.000027553\n",
      "\t\t Running 28th iteration on G\n",
      "\t\t G Loss is : 0.000020126\n",
      "Currently running epoch Nbr 29\n",
      "\t[1,   100] D loss: 0.000024362\n",
      "\t[1,   200] D loss: 0.000024574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[2,   100] D loss: 0.000024029\n",
      "\t[2,   200] D loss: 0.000025993\n",
      "\t[3,   100] D loss: 0.000026466\n",
      "\t[3,   200] D loss: 0.000023472\n",
      "\t\t Running 29th iteration on G\n",
      "\t\t G Loss is : 0.000020413\n",
      "Currently running epoch Nbr 30\n",
      "\t[1,   100] D loss: 0.000025225\n",
      "\t[1,   200] D loss: 0.000025874\n",
      "\t[2,   100] D loss: 0.000024464\n",
      "\t[2,   200] D loss: 0.000025545\n",
      "\t[3,   100] D loss: 0.000024931\n",
      "\t[3,   200] D loss: 0.000024563\n",
      "\t\t Running 30th iteration on G\n",
      "\t\t G Loss is : 0.000020049\n",
      "Currently running epoch Nbr 31\n",
      "\t[1,   100] D loss: 0.000023694\n",
      "\t[1,   200] D loss: 0.000023242\n",
      "\t[2,   100] D loss: 0.000025735\n",
      "\t[2,   200] D loss: 0.000024762\n",
      "\t[3,   100] D loss: 0.000026091\n",
      "\t[3,   200] D loss: 0.000025363\n",
      "\t\t Running 31th iteration on G\n",
      "\t\t G Loss is : 0.000019440\n",
      "Currently running epoch Nbr 32\n",
      "\t[1,   100] D loss: 0.000023871\n",
      "\t[1,   200] D loss: 0.000024106\n",
      "\t[2,   100] D loss: 0.000025392\n",
      "\t[2,   200] D loss: 0.000024233\n",
      "\t[3,   100] D loss: 0.000022826\n",
      "\t[3,   200] D loss: 0.000026618\n",
      "\t\t Running 32th iteration on G\n",
      "\t\t G Loss is : 0.000019471\n",
      "Currently running epoch Nbr 33\n",
      "\t[1,   100] D loss: 0.000022175\n",
      "\t[1,   200] D loss: 0.000026006\n",
      "\t[2,   100] D loss: 0.000024575\n",
      "\t[2,   200] D loss: 0.000025203\n",
      "\t[3,   100] D loss: 0.000022690\n",
      "\t[3,   200] D loss: 0.000026587\n",
      "\t\t Running 33th iteration on G\n",
      "\t\t G Loss is : 0.000019113\n",
      "Currently running epoch Nbr 34\n",
      "\t[1,   100] D loss: 0.000025844\n",
      "\t[1,   200] D loss: 0.000023686\n",
      "\t[2,   100] D loss: 0.000023027\n",
      "\t[2,   200] D loss: 0.000022455\n",
      "\t[3,   100] D loss: 0.000022109\n",
      "\t[3,   200] D loss: 0.000024666\n",
      "\t\t Running 34th iteration on G\n",
      "\t\t G Loss is : 0.000019004\n",
      "Currently running epoch Nbr 35\n",
      "\t[1,   100] D loss: 0.000021355\n",
      "\t[1,   200] D loss: 0.000024356\n",
      "\t[2,   100] D loss: 0.000024778\n",
      "\t[2,   200] D loss: 0.000023189\n",
      "\t[3,   100] D loss: 0.000021683\n",
      "\t[3,   200] D loss: 0.000027204\n",
      "\t\t Running 35th iteration on G\n",
      "\t\t G Loss is : 0.000018983\n",
      "Currently running epoch Nbr 36\n",
      "\t[1,   100] D loss: 0.000023646\n",
      "\t[1,   200] D loss: 0.000023798\n",
      "\t[2,   100] D loss: 0.000022429\n",
      "\t[2,   200] D loss: 0.000025450\n",
      "\t[3,   100] D loss: 0.000024584\n",
      "\t[3,   200] D loss: 0.000022003\n",
      "\t\t Running 36th iteration on G\n",
      "\t\t G Loss is : 0.000018380\n",
      "Currently running epoch Nbr 37\n",
      "\t[1,   100] D loss: 0.000024672\n",
      "\t[1,   200] D loss: 0.000022634\n",
      "\t[2,   100] D loss: 0.000022113\n",
      "\t[2,   200] D loss: 0.000021743\n",
      "\t[3,   100] D loss: 0.000023361\n",
      "\t[3,   200] D loss: 0.000023521\n",
      "\t\t Running 37th iteration on G\n",
      "\t\t G Loss is : 0.000019022\n",
      "Currently running epoch Nbr 38\n",
      "\t[1,   100] D loss: 0.000022697\n",
      "\t[1,   200] D loss: 0.000021596\n",
      "\t[2,   100] D loss: 0.000020588\n",
      "\t[2,   200] D loss: 0.000025554\n",
      "\t[3,   100] D loss: 0.000022896\n",
      "\t[3,   200] D loss: 0.000022590\n",
      "\t\t Running 38th iteration on G\n",
      "\t\t G Loss is : 0.000018615\n",
      "Currently running epoch Nbr 39\n",
      "\t[1,   100] D loss: 0.000023763\n",
      "\t[1,   200] D loss: 0.000020846\n",
      "\t[2,   100] D loss: 0.000024319\n",
      "\t[2,   200] D loss: 0.000021794\n",
      "\t[3,   100] D loss: 0.000021316\n",
      "\t[3,   200] D loss: 0.000024096\n",
      "\t\t Running 39th iteration on G\n",
      "\t\t G Loss is : 0.000017796\n",
      "Currently running epoch Nbr 40\n",
      "\t[1,   100] D loss: 0.000022336\n",
      "\t[1,   200] D loss: 0.000023523\n",
      "\t[2,   100] D loss: 0.000022289\n",
      "\t[2,   200] D loss: 0.000022381\n",
      "\t[3,   100] D loss: 0.000025016\n",
      "\t[3,   200] D loss: 0.000020686\n",
      "\t\t Running 40th iteration on G\n",
      "\t\t G Loss is : 0.000017967\n",
      "Currently running epoch Nbr 41\n",
      "\t[1,   100] D loss: 0.000019544\n",
      "\t[1,   200] D loss: 0.000025027\n",
      "\t[2,   100] D loss: 0.000022280\n",
      "\t[2,   200] D loss: 0.000022972\n",
      "\t[3,   100] D loss: 0.000023041\n",
      "\t[3,   200] D loss: 0.000022073\n",
      "\t\t Running 41th iteration on G\n",
      "\t\t G Loss is : 0.000017180\n",
      "Currently running epoch Nbr 42\n",
      "\t[1,   100] D loss: 0.000022539\n",
      "\t[1,   200] D loss: 0.000021156\n",
      "\t[2,   100] D loss: 0.000022422\n",
      "\t[2,   200] D loss: 0.000022281\n",
      "\t[3,   100] D loss: 0.000020455\n",
      "\t[3,   200] D loss: 0.000023783\n",
      "\t\t Running 42th iteration on G\n",
      "\t\t G Loss is : 0.000017623\n",
      "Currently running epoch Nbr 43\n",
      "\t[1,   100] D loss: 0.000023288\n",
      "\t[1,   200] D loss: 0.000021027\n",
      "\t[2,   100] D loss: 0.000022271\n",
      "\t[2,   200] D loss: 0.000020023\n",
      "\t[3,   100] D loss: 0.000021889\n",
      "\t[3,   200] D loss: 0.000021030\n",
      "\t\t Running 43th iteration on G\n",
      "\t\t G Loss is : 0.000017517\n",
      "Currently running epoch Nbr 44\n",
      "\t[1,   100] D loss: 0.000022653\n",
      "\t[1,   200] D loss: 0.000020656\n",
      "\t[2,   100] D loss: 0.000020518\n",
      "\t[2,   200] D loss: 0.000021590\n",
      "\t[3,   100] D loss: 0.000021683\n",
      "\t[3,   200] D loss: 0.000022201\n",
      "\t\t Running 44th iteration on G\n",
      "\t\t G Loss is : 0.000016605\n",
      "Currently running epoch Nbr 45\n",
      "\t[1,   100] D loss: 0.000019489\n",
      "\t[1,   200] D loss: 0.000023163\n",
      "\t[2,   100] D loss: 0.000023476\n",
      "\t[2,   200] D loss: 0.000019844\n",
      "\t[3,   100] D loss: 0.000022134\n",
      "\t[3,   200] D loss: 0.000019895\n",
      "\t\t Running 45th iteration on G\n",
      "\t\t G Loss is : 0.000016373\n",
      "Currently running epoch Nbr 46\n",
      "\t[1,   100] D loss: 0.000023046\n",
      "\t[1,   200] D loss: 0.000019440\n",
      "\t[2,   100] D loss: 0.000021153\n",
      "\t[2,   200] D loss: 0.000019891\n",
      "\t[3,   100] D loss: 0.000021084\n",
      "\t[3,   200] D loss: 0.000021544\n",
      "\t\t Running 46th iteration on G\n",
      "\t\t G Loss is : 0.000016674\n",
      "Currently running epoch Nbr 47\n",
      "\t[1,   100] D loss: 0.000020351\n",
      "\t[1,   200] D loss: 0.000019240\n",
      "\t[2,   100] D loss: 0.000021276\n",
      "\t[2,   200] D loss: 0.000021108\n",
      "\t[3,   100] D loss: 0.000020571\n",
      "\t[3,   200] D loss: 0.000019004\n",
      "\t\t Running 47th iteration on G\n",
      "\t\t G Loss is : 0.000016349\n",
      "Currently running epoch Nbr 48\n",
      "\t[1,   100] D loss: 0.000020961\n",
      "\t[1,   200] D loss: 0.000020532\n",
      "\t[2,   100] D loss: 0.000020907\n",
      "\t[2,   200] D loss: 0.000019976\n",
      "\t[3,   100] D loss: 0.000019496\n",
      "\t[3,   200] D loss: 0.000021042\n",
      "\t\t Running 48th iteration on G\n",
      "\t\t G Loss is : 0.000016219\n",
      "Currently running epoch Nbr 49\n",
      "\t[1,   100] D loss: 0.000020586\n",
      "\t[1,   200] D loss: 0.000020519\n",
      "\t[2,   100] D loss: 0.000021100\n",
      "\t[2,   200] D loss: 0.000020639\n",
      "\t[3,   100] D loss: 0.000019386\n",
      "\t[3,   200] D loss: 0.000020846\n",
      "\t\t Running 49th iteration on G\n",
      "\t\t G Loss is : 0.000016020\n",
      "Currently running epoch Nbr 50\n",
      "\t[1,   100] D loss: 0.000019890\n",
      "\t[1,   200] D loss: 0.000020434\n",
      "\t[2,   100] D loss: 0.000019465\n",
      "\t[2,   200] D loss: 0.000021664\n",
      "\t[3,   100] D loss: 0.000020479\n",
      "\t[3,   200] D loss: 0.000020241\n",
      "\t\t Running 50th iteration on G\n",
      "\t\t G Loss is : 0.000015896\n",
      "Currently running epoch Nbr 51\n",
      "\t[1,   100] D loss: 0.000019726\n",
      "\t[1,   200] D loss: 0.000021236\n",
      "\t[2,   100] D loss: 0.000018581\n",
      "\t[2,   200] D loss: 0.000020087\n",
      "\t[3,   100] D loss: 0.000018763\n",
      "\t[3,   200] D loss: 0.000019697\n",
      "\t\t Running 51th iteration on G\n",
      "\t\t G Loss is : 0.000015574\n",
      "Currently running epoch Nbr 52\n",
      "\t[1,   100] D loss: 0.000019293\n",
      "\t[1,   200] D loss: 0.000020410\n",
      "\t[2,   100] D loss: 0.000018155\n",
      "\t[2,   200] D loss: 0.000020826\n",
      "\t[3,   100] D loss: 0.000019488\n",
      "\t[3,   200] D loss: 0.000019794\n",
      "\t\t Running 52th iteration on G\n",
      "\t\t G Loss is : 0.000015428\n",
      "Currently running epoch Nbr 53\n",
      "\t[1,   100] D loss: 0.000020847\n",
      "\t[1,   200] D loss: 0.000017694\n",
      "\t[2,   100] D loss: 0.000019302\n",
      "\t[2,   200] D loss: 0.000017895\n",
      "\t[3,   100] D loss: 0.000018452\n",
      "\t[3,   200] D loss: 0.000019276\n",
      "\t\t Running 53th iteration on G\n",
      "\t\t G Loss is : 0.000014684\n",
      "Currently running epoch Nbr 54\n",
      "\t[1,   100] D loss: 0.000020277\n",
      "\t[1,   200] D loss: 0.000017944\n",
      "\t[2,   100] D loss: 0.000020683\n",
      "\t[2,   200] D loss: 0.000018307\n",
      "\t[3,   100] D loss: 0.000018807\n",
      "\t[3,   200] D loss: 0.000020498\n",
      "\t\t Running 54th iteration on G\n",
      "\t\t G Loss is : 0.000014995\n",
      "Currently running epoch Nbr 55\n",
      "\t[1,   100] D loss: 0.000017378\n",
      "\t[1,   200] D loss: 0.000020389\n",
      "\t[2,   100] D loss: 0.000018263\n",
      "\t[2,   200] D loss: 0.000018267\n",
      "\t[3,   100] D loss: 0.000017883\n",
      "\t[3,   200] D loss: 0.000018314\n",
      "\t\t Running 55th iteration on G\n",
      "\t\t G Loss is : 0.000014851\n",
      "Currently running epoch Nbr 56\n",
      "\t[1,   100] D loss: 0.000018830\n",
      "\t[1,   200] D loss: 0.000020110\n",
      "\t[2,   100] D loss: 0.000018885\n",
      "\t[2,   200] D loss: 0.000019324\n",
      "\t[3,   100] D loss: 0.000017583\n",
      "\t[3,   200] D loss: 0.000020710\n",
      "\t\t Running 56th iteration on G\n",
      "\t\t G Loss is : 0.000014847\n",
      "Currently running epoch Nbr 57\n",
      "\t[1,   100] D loss: 0.000018672\n",
      "\t[1,   200] D loss: 0.000019568\n",
      "\t[2,   100] D loss: 0.000018914\n",
      "\t[2,   200] D loss: 0.000017993\n",
      "\t[3,   100] D loss: 0.000018066\n",
      "\t[3,   200] D loss: 0.000019354\n",
      "\t\t Running 57th iteration on G\n",
      "\t\t G Loss is : 0.000014602\n",
      "Currently running epoch Nbr 58\n",
      "\t[1,   100] D loss: 0.000019006\n",
      "\t[1,   200] D loss: 0.000016918\n",
      "\t[2,   100] D loss: 0.000016390\n",
      "\t[2,   200] D loss: 0.000020539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[3,   100] D loss: 0.000018780\n",
      "\t[3,   200] D loss: 0.000018721\n",
      "\t\t Running 58th iteration on G\n",
      "\t\t G Loss is : 0.000014596\n",
      "Currently running epoch Nbr 59\n",
      "\t[1,   100] D loss: 0.000017894\n",
      "\t[1,   200] D loss: 0.000019436\n",
      "\t[2,   100] D loss: 0.000018616\n",
      "\t[2,   200] D loss: 0.000018571\n",
      "\t[3,   100] D loss: 0.000018303\n",
      "\t[3,   200] D loss: 0.000017535\n",
      "\t\t Running 59th iteration on G\n",
      "\t\t G Loss is : 0.000014601\n",
      "Currently running epoch Nbr 60\n",
      "\t[1,   100] D loss: 0.000016830\n",
      "\t[1,   200] D loss: 0.000018230\n",
      "\t[2,   100] D loss: 0.000016738\n",
      "\t[2,   200] D loss: 0.000017650\n",
      "\t[3,   100] D loss: 0.000018871\n",
      "\t[3,   200] D loss: 0.000017774\n",
      "\t\t Running 60th iteration on G\n",
      "\t\t G Loss is : 0.000014234\n",
      "Currently running epoch Nbr 61\n",
      "\t[1,   100] D loss: 0.000017233\n",
      "\t[1,   200] D loss: 0.000017782\n",
      "\t[2,   100] D loss: 0.000017059\n",
      "\t[2,   200] D loss: 0.000018577\n",
      "\t[3,   100] D loss: 0.000018093\n",
      "\t[3,   200] D loss: 0.000018512\n",
      "\t\t Running 61th iteration on G\n",
      "\t\t G Loss is : 0.000014342\n",
      "Currently running epoch Nbr 62\n",
      "\t[1,   100] D loss: 0.000018211\n",
      "\t[1,   200] D loss: 0.000016083\n",
      "\t[2,   100] D loss: 0.000019672\n",
      "\t[2,   200] D loss: 0.000016387\n",
      "\t[3,   100] D loss: 0.000015858\n",
      "\t[3,   200] D loss: 0.000018913\n",
      "\t\t Running 62th iteration on G\n",
      "\t\t G Loss is : 0.000013982\n",
      "Currently running epoch Nbr 63\n",
      "\t[1,   100] D loss: 0.000017640\n",
      "\t[1,   200] D loss: 0.000018546\n",
      "\t[2,   100] D loss: 0.000018761\n",
      "\t[2,   200] D loss: 0.000017137\n",
      "\t[3,   100] D loss: 0.000015687\n",
      "\t[3,   200] D loss: 0.000019244\n",
      "\t\t Running 63th iteration on G\n",
      "\t\t G Loss is : 0.000014028\n",
      "Currently running epoch Nbr 64\n",
      "\t[1,   100] D loss: 0.000018364\n",
      "\t[1,   200] D loss: 0.000017121\n",
      "\t[2,   100] D loss: 0.000018108\n",
      "\t[2,   200] D loss: 0.000017190\n",
      "\t[3,   100] D loss: 0.000017545\n",
      "\t[3,   200] D loss: 0.000016600\n",
      "\t\t Running 64th iteration on G\n",
      "\t\t G Loss is : 0.000013718\n",
      "Currently running epoch Nbr 65\n",
      "\t[1,   100] D loss: 0.000016466\n",
      "\t[1,   200] D loss: 0.000017291\n",
      "\t[2,   100] D loss: 0.000018311\n",
      "\t[2,   200] D loss: 0.000016815\n",
      "\t[3,   100] D loss: 0.000015823\n",
      "\t[3,   200] D loss: 0.000019117\n",
      "\t\t Running 65th iteration on G\n",
      "\t\t G Loss is : 0.000013567\n",
      "Currently running epoch Nbr 66\n",
      "\t[1,   100] D loss: 0.000016097\n",
      "\t[1,   200] D loss: 0.000018865\n",
      "\t[2,   100] D loss: 0.000016928\n",
      "\t[2,   200] D loss: 0.000015156\n",
      "\t[3,   100] D loss: 0.000017701\n",
      "\t[3,   200] D loss: 0.000015717\n",
      "\t\t Running 66th iteration on G\n",
      "\t\t G Loss is : 0.000013249\n",
      "Currently running epoch Nbr 67\n",
      "\t[1,   100] D loss: 0.000017196\n",
      "\t[1,   200] D loss: 0.000017360\n",
      "\t[2,   100] D loss: 0.000015799\n",
      "\t[2,   200] D loss: 0.000017855\n",
      "\t[3,   100] D loss: 0.000015920\n",
      "\t[3,   200] D loss: 0.000015574\n",
      "\t\t Running 67th iteration on G\n",
      "\t\t G Loss is : 0.000013330\n",
      "Currently running epoch Nbr 68\n",
      "\t[1,   100] D loss: 0.000015505\n",
      "\t[1,   200] D loss: 0.000019247\n",
      "\t[2,   100] D loss: 0.000016731\n",
      "\t[2,   200] D loss: 0.000016142\n",
      "\t[3,   100] D loss: 0.000015831\n",
      "\t[3,   200] D loss: 0.000017844\n",
      "\t\t Running 68th iteration on G\n",
      "\t\t G Loss is : 0.000013001\n",
      "Currently running epoch Nbr 69\n",
      "\t[1,   100] D loss: 0.000017649\n",
      "\t[1,   200] D loss: 0.000016229\n",
      "\t[2,   100] D loss: 0.000018172\n",
      "\t[2,   200] D loss: 0.000014863\n",
      "\t[3,   100] D loss: 0.000016455\n",
      "\t[3,   200] D loss: 0.000017541\n",
      "\t\t Running 69th iteration on G\n",
      "\t\t G Loss is : 0.000013270\n",
      "Currently running epoch Nbr 70\n",
      "\t[1,   100] D loss: 0.000017227\n",
      "\t[1,   200] D loss: 0.000016768\n",
      "\t[2,   100] D loss: 0.000015086\n",
      "\t[2,   200] D loss: 0.000018899\n",
      "\t[3,   100] D loss: 0.000015571\n",
      "\t[3,   200] D loss: 0.000016910\n",
      "\t\t Running 70th iteration on G\n",
      "\t\t G Loss is : 0.000013195\n",
      "Currently running epoch Nbr 71\n",
      "\t[1,   100] D loss: 0.000017109\n",
      "\t[1,   200] D loss: 0.000015487\n",
      "\t[2,   100] D loss: 0.000017142\n",
      "\t[2,   200] D loss: 0.000015824\n",
      "\t[3,   100] D loss: 0.000014584\n",
      "\t[3,   200] D loss: 0.000018323\n",
      "\t\t Running 71th iteration on G\n",
      "\t\t G Loss is : 0.000012743\n",
      "Currently running epoch Nbr 72\n",
      "\t[1,   100] D loss: 0.000015006\n",
      "\t[1,   200] D loss: 0.000017523\n",
      "\t[2,   100] D loss: 0.000015313\n",
      "\t[2,   200] D loss: 0.000015677\n",
      "\t[3,   100] D loss: 0.000016110\n",
      "\t[3,   200] D loss: 0.000016079\n",
      "\t\t Running 72th iteration on G\n",
      "\t\t G Loss is : 0.000012663\n",
      "Currently running epoch Nbr 73\n",
      "\t[1,   100] D loss: 0.000017238\n",
      "\t[1,   200] D loss: 0.000015025\n",
      "\t[2,   100] D loss: 0.000015399\n",
      "\t[2,   200] D loss: 0.000016221\n",
      "\t[3,   100] D loss: 0.000014704\n",
      "\t[3,   200] D loss: 0.000015821\n",
      "\t\t Running 73th iteration on G\n",
      "\t\t G Loss is : 0.000012637\n",
      "Currently running epoch Nbr 74\n",
      "\t[1,   100] D loss: 0.000014729\n",
      "\t[1,   200] D loss: 0.000015985\n",
      "\t[2,   100] D loss: 0.000016626\n",
      "\t[2,   200] D loss: 0.000015314\n",
      "\t[3,   100] D loss: 0.000016619\n",
      "\t[3,   200] D loss: 0.000016097\n",
      "\t\t Running 74th iteration on G\n",
      "\t\t G Loss is : 0.000012514\n",
      "Currently running epoch Nbr 75\n",
      "\t[1,   100] D loss: 0.000014346\n",
      "\t[1,   200] D loss: 0.000016249\n",
      "\t[2,   100] D loss: 0.000014526\n",
      "\t[2,   200] D loss: 0.000017009\n",
      "\t[3,   100] D loss: 0.000016615\n",
      "\t[3,   200] D loss: 0.000014994\n",
      "\t\t Running 75th iteration on G\n",
      "\t\t G Loss is : 0.000012245\n",
      "Currently running epoch Nbr 76\n",
      "\t[1,   100] D loss: 0.000014286\n",
      "\t[1,   200] D loss: 0.000015042\n",
      "\t[2,   100] D loss: 0.000016884\n",
      "\t[2,   200] D loss: 0.000015100\n",
      "\t[3,   100] D loss: 0.000014610\n",
      "\t[3,   200] D loss: 0.000015290\n",
      "\t\t Running 76th iteration on G\n",
      "\t\t G Loss is : 0.000012147\n",
      "Currently running epoch Nbr 77\n",
      "\t[1,   100] D loss: 0.000016305\n",
      "\t[1,   200] D loss: 0.000014593\n",
      "\t[2,   100] D loss: 0.000014503\n",
      "\t[2,   200] D loss: 0.000016279\n",
      "\t[3,   100] D loss: 0.000014544\n",
      "\t[3,   200] D loss: 0.000015723\n",
      "\t\t Running 77th iteration on G\n",
      "\t\t G Loss is : 0.000012309\n",
      "Currently running epoch Nbr 78\n",
      "\t[1,   100] D loss: 0.000017377\n",
      "\t[1,   200] D loss: 0.000013876\n",
      "\t[2,   100] D loss: 0.000013867\n",
      "\t[2,   200] D loss: 0.000016712\n",
      "\t[3,   100] D loss: 0.000013884\n",
      "\t[3,   200] D loss: 0.000015558\n",
      "\t\t Running 78th iteration on G\n",
      "\t\t G Loss is : 0.000012093\n",
      "Currently running epoch Nbr 79\n",
      "\t[1,   100] D loss: 0.000015096\n",
      "\t[1,   200] D loss: 0.000015828\n",
      "\t[2,   100] D loss: 0.000015590\n",
      "\t[2,   200] D loss: 0.000015668\n",
      "\t[3,   100] D loss: 0.000014971\n",
      "\t[3,   200] D loss: 0.000015101\n",
      "\t\t Running 79th iteration on G\n",
      "\t\t G Loss is : 0.000012181\n",
      "Currently running epoch Nbr 80\n",
      "\t[1,   100] D loss: 0.000015566\n",
      "\t[1,   200] D loss: 0.000014436\n",
      "\t[2,   100] D loss: 0.000014374\n",
      "\t[2,   200] D loss: 0.000015913\n",
      "\t[3,   100] D loss: 0.000013851\n",
      "\t[3,   200] D loss: 0.000015439\n",
      "\t\t Running 80th iteration on G\n",
      "\t\t G Loss is : 0.000011730\n",
      "Currently running epoch Nbr 81\n",
      "\t[1,   100] D loss: 0.000016334\n",
      "\t[1,   200] D loss: 0.000013816\n",
      "\t[2,   100] D loss: 0.000013414\n",
      "\t[2,   200] D loss: 0.000015666\n",
      "\t[3,   100] D loss: 0.000014909\n",
      "\t[3,   200] D loss: 0.000014103\n",
      "\t\t Running 81th iteration on G\n",
      "\t\t G Loss is : 0.000011710\n",
      "Currently running epoch Nbr 82\n",
      "\t[1,   100] D loss: 0.000014282\n",
      "\t[1,   200] D loss: 0.000016029\n",
      "\t[2,   100] D loss: 0.000013421\n",
      "\t[2,   200] D loss: 0.000014828\n",
      "\t[3,   100] D loss: 0.000014633\n",
      "\t[3,   200] D loss: 0.000015251\n",
      "\t\t Running 82th iteration on G\n",
      "\t\t G Loss is : 0.000011733\n",
      "Currently running epoch Nbr 83\n",
      "\t[1,   100] D loss: 0.000014234\n",
      "\t[1,   200] D loss: 0.000015697\n",
      "\t[2,   100] D loss: 0.000014890\n",
      "\t[2,   200] D loss: 0.000015145\n",
      "\t[3,   100] D loss: 0.000014768\n",
      "\t[3,   200] D loss: 0.000014913\n",
      "\t\t Running 83th iteration on G\n",
      "\t\t G Loss is : 0.000011523\n",
      "Currently running epoch Nbr 84\n",
      "\t[1,   100] D loss: 0.000015679\n",
      "\t[1,   200] D loss: 0.000014311\n",
      "\t[2,   100] D loss: 0.000013644\n",
      "\t[2,   200] D loss: 0.000014730\n",
      "\t[3,   100] D loss: 0.000015604\n",
      "\t[3,   200] D loss: 0.000013637\n",
      "\t\t Running 84th iteration on G\n",
      "\t\t G Loss is : 0.000011672\n",
      "Currently running epoch Nbr 85\n",
      "\t[1,   100] D loss: 0.000013681\n",
      "\t[1,   200] D loss: 0.000015394\n",
      "\t[2,   100] D loss: 0.000014373\n",
      "\t[2,   200] D loss: 0.000012740\n",
      "\t[3,   100] D loss: 0.000013702\n",
      "\t[3,   200] D loss: 0.000015917\n",
      "\t\t Running 85th iteration on G\n",
      "\t\t G Loss is : 0.000011443\n",
      "Currently running epoch Nbr 86\n",
      "\t[1,   100] D loss: 0.000014758\n",
      "\t[1,   200] D loss: 0.000013772\n",
      "\t[2,   100] D loss: 0.000015424\n",
      "\t[2,   200] D loss: 0.000013526\n",
      "\t[3,   100] D loss: 0.000015374\n",
      "\t[3,   200] D loss: 0.000014042\n",
      "\t\t Running 86th iteration on G\n",
      "\t\t G Loss is : 0.000011019\n",
      "Currently running epoch Nbr 87\n",
      "\t[1,   100] D loss: 0.000014956\n",
      "\t[1,   200] D loss: 0.000013500\n",
      "\t[2,   100] D loss: 0.000014481\n",
      "\t[2,   200] D loss: 0.000014928\n",
      "\t[3,   100] D loss: 0.000014799\n",
      "\t[3,   200] D loss: 0.000014030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Running 87th iteration on G\n",
      "\t\t G Loss is : 0.000011130\n",
      "Currently running epoch Nbr 88\n",
      "\t[1,   100] D loss: 0.000015709\n",
      "\t[1,   200] D loss: 0.000013200\n",
      "\t[2,   100] D loss: 0.000013019\n",
      "\t[2,   200] D loss: 0.000014962\n",
      "\t[3,   100] D loss: 0.000014003\n",
      "\t[3,   200] D loss: 0.000013517\n",
      "\t\t Running 88th iteration on G\n",
      "\t\t G Loss is : 0.000011011\n",
      "Currently running epoch Nbr 89\n",
      "\t[1,   100] D loss: 0.000014031\n",
      "\t[1,   200] D loss: 0.000014417\n",
      "\t[2,   100] D loss: 0.000013972\n",
      "\t[2,   200] D loss: 0.000014184\n",
      "\t[3,   100] D loss: 0.000012755\n",
      "\t[3,   200] D loss: 0.000014205\n",
      "\t\t Running 89th iteration on G\n",
      "\t\t G Loss is : 0.000011113\n",
      "Currently running epoch Nbr 90\n",
      "\t[1,   100] D loss: 0.000012769\n",
      "\t[1,   200] D loss: 0.000015181\n",
      "\t[2,   100] D loss: 0.000014334\n",
      "\t[2,   200] D loss: 0.000013797\n",
      "\t[3,   100] D loss: 0.000013776\n",
      "\t[3,   200] D loss: 0.000013213\n",
      "\t\t Running 90th iteration on G\n",
      "\t\t G Loss is : 0.000011230\n",
      "Currently running epoch Nbr 91\n",
      "\t[1,   100] D loss: 0.000013245\n",
      "\t[1,   200] D loss: 0.000014251\n",
      "\t[2,   100] D loss: 0.000014205\n",
      "\t[2,   200] D loss: 0.000013086\n",
      "\t[3,   100] D loss: 0.000013058\n",
      "\t[3,   200] D loss: 0.000015361\n",
      "\t\t Running 91th iteration on G\n",
      "\t\t G Loss is : 0.000010547\n",
      "Currently running epoch Nbr 92\n",
      "\t[1,   100] D loss: 0.000012597\n",
      "\t[1,   200] D loss: 0.000014626\n",
      "\t[2,   100] D loss: 0.000013025\n",
      "\t[2,   200] D loss: 0.000015016\n",
      "\t[3,   100] D loss: 0.000014371\n",
      "\t[3,   200] D loss: 0.000013361\n",
      "\t\t Running 92th iteration on G\n",
      "\t\t G Loss is : 0.000010831\n",
      "Currently running epoch Nbr 93\n",
      "\t[1,   100] D loss: 0.000013920\n",
      "\t[1,   200] D loss: 0.000014145\n",
      "\t[2,   100] D loss: 0.000013220\n",
      "\t[2,   200] D loss: 0.000012543\n",
      "\t[3,   100] D loss: 0.000014563\n",
      "\t[3,   200] D loss: 0.000013290\n",
      "\t\t Running 93th iteration on G\n",
      "\t\t G Loss is : 0.000010387\n",
      "Currently running epoch Nbr 94\n",
      "\t[1,   100] D loss: 0.000014729\n",
      "\t[1,   200] D loss: 0.000012559\n",
      "\t[2,   100] D loss: 0.000012918\n",
      "\t[2,   200] D loss: 0.000014720\n",
      "\t[3,   100] D loss: 0.000012384\n",
      "\t[3,   200] D loss: 0.000013112\n",
      "\t\t Running 94th iteration on G\n",
      "\t\t G Loss is : 0.000010468\n",
      "Currently running epoch Nbr 95\n",
      "\t[1,   100] D loss: 0.000012514\n",
      "\t[1,   200] D loss: 0.000013363\n",
      "\t[2,   100] D loss: 0.000014169\n",
      "\t[2,   200] D loss: 0.000012819\n",
      "\t[3,   100] D loss: 0.000012417\n",
      "\t[3,   200] D loss: 0.000013986\n",
      "\t\t Running 95th iteration on G\n",
      "\t\t G Loss is : 0.000010636\n",
      "Currently running epoch Nbr 96\n",
      "\t[1,   100] D loss: 0.000015156\n",
      "\t[1,   200] D loss: 0.000012124\n",
      "\t[2,   100] D loss: 0.000014341\n",
      "\t[2,   200] D loss: 0.000012578\n",
      "\t[3,   100] D loss: 0.000012127\n",
      "\t[3,   200] D loss: 0.000014206\n",
      "\t\t Running 96th iteration on G\n",
      "\t\t G Loss is : 0.000010217\n",
      "Currently running epoch Nbr 97\n",
      "\t[1,   100] D loss: 0.000012665\n",
      "\t[1,   200] D loss: 0.000013214\n",
      "\t[2,   100] D loss: 0.000014177\n",
      "\t[2,   200] D loss: 0.000012778\n",
      "\t[3,   100] D loss: 0.000012198\n",
      "\t[3,   200] D loss: 0.000014406\n",
      "\t\t Running 97th iteration on G\n",
      "\t\t G Loss is : 0.000010237\n",
      "Currently running epoch Nbr 98\n",
      "\t[1,   100] D loss: 0.000013399\n",
      "\t[1,   200] D loss: 0.000012749\n",
      "\t[2,   100] D loss: 0.000013282\n",
      "\t[2,   200] D loss: 0.000013638\n",
      "\t[3,   100] D loss: 0.000014278\n",
      "\t[3,   200] D loss: 0.000012580\n",
      "\t\t Running 98th iteration on G\n",
      "\t\t G Loss is : 0.000010650\n",
      "Currently running epoch Nbr 99\n",
      "\t[1,   100] D loss: 0.000012765\n",
      "\t[1,   200] D loss: 0.000012975\n",
      "\t[2,   100] D loss: 0.000011579\n",
      "\t[2,   200] D loss: 0.000012425\n",
      "\t[3,   100] D loss: 0.000013068\n",
      "\t[3,   200] D loss: 0.000012147\n",
      "\t\t Running 99th iteration on G\n",
      "\t\t G Loss is : 0.000010540\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Define a Loss function and optimizer\n",
    "optimizer1 = optim.SGD(D.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer2 = optim.SGD(G.parameters(), lr=0.001, momentum=0.9)\n",
    "# k = discriminator interations\n",
    "k = 3\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(100):\n",
    "    print(\"Currently running epoch Nbr %d\" % epoch)\n",
    "    \n",
    "    # train D for k iterations \n",
    "    for d in range(k):\n",
    "        #print(\"\\tRunning D iteration Nbr %d\" % d)\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer1.zero_grad()\n",
    "            # sample batch_size * 10 matrix of uniform distributed noise\n",
    "            noise = sample_noise(batch_size).to(device)\n",
    "            outputs_fake = D(G(noise).detach())\n",
    "            outputs_real = D(inputs)\n",
    "            loss = criterion(outputs_real, labels_real) + criterion(outputs_fake, labels_fake)\n",
    "            loss.backward()\n",
    "            optimizer1.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:   # print every 1000 mini-batches\n",
    "                print('\\t[%d, %5d] D loss: %.9f' %\n",
    "                      (d + 1, i + 1, running_loss / 99))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    # 1 training step for G\n",
    "    print(\"\\t\\t Running %dth iteration on G\" % epoch)\n",
    "    optimizer2.zero_grad()\n",
    "    noise = sample_noise(batch_size).to(device)\n",
    "    loss = criterion(D(G(noise)), labels_fake)\n",
    "    loss.backward()\n",
    "    optimizer2.step()\n",
    "    print(\"\\t\\t G Loss is : %.9f\" % loss.item())\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1523e-05, 9.9999e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 2.6877e-07]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = sample_noise(1).cuda()\n",
    "\n",
    "a = G(s)\n",
    "\n",
    "a = torch.reshape(G(s), (28,28)).cpu()\n",
    "img = torchvision.utils.make_grid(a)\n",
    "\n",
    "img = img / 2 + 0.5     # unnormalize\n",
    "npimg = img.detach().numpy()\n",
    "#plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.imshow(np.transpose(a.detach().numpy(), (0, 1)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(D(G(s).detach()))\n",
    "\n",
    "\n",
    "trainloader, validation_loader, test_loader = load_mnist_minibatched(batch_size)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(D(images[0].to(device)))\n",
    "\n",
    "img = torchvision.utils.make_grid(images[0])\n",
    "\n",
    "#img = img / 2 + 0.5\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
