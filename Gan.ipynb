{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adverserial Network for Fake Image Generation\n",
    "\n",
    "In this Notebook, we will train an FC-GAN to genereate fake Mnist data.\n",
    "\n",
    "Followed by a conversion of the FC-GAN to DC-GAN, and the generation of higher resolution images.\n",
    "\n",
    "Gan Paper: https://arxiv.org/abs/1406.2661\n",
    "\n",
    "PyTorch MNist dataset : https://pytorch.org/docs/stable/torchvision/datasets.html#mnist\n",
    "\n",
    "Convert FC-Gan To DC-Gan Paper : https://arxiv.org/pdf/1511.06434.pdf\n",
    "\n",
    "List of tricks to train GANs: https://github.com/soumith/ganhacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "import os\n",
    "from typing import Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.tensor as tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC-GAN for the Generation of Fake MNIST Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frist load the MNist dataset from pytorch\n",
    "\n",
    "def load_mnist_minibatched(batch_size: int, n_train: int = 8192, n_valid: int = 1024,\n",
    "                           valid_test_batch_size: int = 1024) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='../data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='../data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(range(n_train))\n",
    "    validation_sampler = SubsetRandomSampler(range(n_train, n_train+n_valid))\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    validation_loader = DataLoader(dataset=train_dataset, batch_size=valid_test_batch_size,\n",
    "                                   sampler=validation_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=valid_test_batch_size, \n",
    "                                              shuffle=False)\n",
    "    return train_loader, validation_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what the MNist data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7     5     2     0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "trainloader, validation_loader, test_loader = load_mnist_minibatched(batch_size)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "\n",
    "img = torchvision.utils.make_grid(images[:4,:,:,:])\n",
    "\n",
    "# show images\n",
    "img = img / 2 + 0.5     # unnormalize\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The adverserial Networks:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Generative Network:\n",
    "\n",
    "Input: x values sampled from uniform distribution\n",
    "\n",
    "Output: 32 x 32 Image, that should look like the data from MNist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Generative Network\n",
    "\n",
    "class generativeNet(nn.Module):\n",
    "    \"\"\"\n",
    "        The CNN convolutional network with architecture defined above\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 10, out_features=6 * 6)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features= 6 * 6, out_features=12 * 12)\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features= 12 * 12, out_features=24 * 24)\n",
    "        \n",
    "        self.fc4 = nn.Linear(in_features= 24 * 24, out_features=28 * 28)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            x: The input tensor with shape [batch_size, feature_dim] (minibatch of data)\n",
    "        Returns:\n",
    "            scores: Pytorch tensor of shape (N, C) giving classification scores for x\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc4(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The discriminative network:\n",
    "\n",
    "Input: Takes 32 x 32 Image as Input\n",
    "Output: probability of it being real data (non generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class discrimNet(nn.Module):\n",
    "    \"\"\"\n",
    "        The CNN convolutional network with architecture defined above\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 28 * 28, out_features=22 * 22)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features= 22 * 22, out_features=12 * 12)\n",
    "        \n",
    "        self.fc3 = nn.Linear(in_features= 12 * 12, out_features=6 * 6)\n",
    "        \n",
    "        # 2 class fake and real data\n",
    "        self.fc4 = nn.Linear(in_features= 6 * 6, out_features=2)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: The input tensor with shape [batch_size, feature_dim] (minibatch of data)\n",
    "        Returns:\n",
    "            scores: Pytorch tensor of shape (N, C) giving classification scores for x\n",
    "        \"\"\"\n",
    "        \n",
    "        x = x.view(x.shape[0], 28 * 28)\n",
    "    \n",
    "        x = self.fc1(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.fc4(x)        \n",
    "        return self.soft(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define The Noise Prior for the Generative Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64629791 0.23419249 0.68541793 0.76016939 0.34297624 0.24666436\n",
      " 0.80726976 0.06034769 0.98901611 0.3604719 ]\n"
     ]
    }
   ],
   "source": [
    "# Define The Noise Distribution, we us the Gaussian Nosie Distribution:\n",
    "\n",
    "# always use the same seed to get the same random variables\n",
    "# np.random.seed(0)\n",
    "\n",
    "# Here is how to sample a vector of 10 values from uniform distribution\n",
    "s = np.random.uniform(0,1, 10)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for sampling the noise data\n",
    "\n",
    "def sample_noise(batch_size=batch_size):\n",
    "    noise_batch = []\n",
    "    for i in range(batch_size):\n",
    "        s = np.random.uniform(0,1, 10) # 10 values sample from uniform distribution\n",
    "        noise_batch.append(s)\n",
    "\n",
    "    noise_batch = torch.from_numpy(np.asarray(noise_batch)).float() \n",
    "    return noise_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the losses\n",
    "\n",
    "def plot_losses(loss_g, loss_d):\n",
    "    xg = [i for i in range(len(loss_g))]\n",
    "    xd = [i for i in range(len(loss_d))]\n",
    "    plt.plot( loss_g, label='g')\n",
    "    plt.plot( loss_d, label='d')\n",
    "\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.title(\"Loss of D ang G\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability(device=None)\n",
    "torch.cuda.get_device_name(device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the real labels\n",
    "a_real = []\n",
    "a_fake = []\n",
    "for i in range(batch_size):\n",
    "    sub1 = [1]\n",
    "    sub2 = [0]\n",
    "    for j in range(1):\n",
    "        sub1.append(0)\n",
    "        sub2.append(1)\n",
    "    a_real.append(sub1)\n",
    "    a_fake.append(sub2)\n",
    "\n",
    "labels_real = torch.tensor(a_real, dtype=torch.float).cuda()\n",
    "labels_fake = torch.tensor(a_fake, dtype=torch.float).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running epoch Nbr 0\n",
      "\t[1,   100] D loss: 1.401772107\n",
      "\t[1,   200] D loss: 1.392696216\n",
      "\t[2,   100] D loss: 1.380007989\n",
      "\t[2,   200] D loss: 1.371098682\n",
      "\t[3,   100] D loss: 1.355137547\n",
      "\t[3,   200] D loss: 1.341766296\n",
      "\t\t Running 0th iteration on G\n",
      "\t[3,   100] G loss: 0.681984059\n",
      "\t[3,   200] G loss: 0.681750427\n",
      "Currently running epoch Nbr 1\n",
      "\t[1,   100] D loss: 1.315697194\n",
      "\t[1,   200] D loss: 1.294366945\n",
      "\t[2,   100] D loss: 1.248953393\n",
      "\t[2,   200] D loss: 1.206604366\n",
      "\t[3,   100] D loss: 1.109246371\n",
      "\t[3,   200] D loss: 1.023026034\n",
      "\t\t Running 1th iteration on G\n",
      "\t[3,   100] G loss: 0.569845327\n",
      "\t[3,   200] G loss: 0.569202176\n",
      "Currently running epoch Nbr 2\n",
      "\t[1,   100] D loss: 0.856606588\n",
      "\t[1,   200] D loss: 0.748371775\n",
      "\t[2,   100] D loss: 0.606667112\n",
      "\t[2,   200] D loss: 0.534019042\n",
      "\t[3,   100] D loss: 0.443598435\n",
      "\t[3,   200] D loss: 0.398016149\n",
      "\t\t Running 2th iteration on G\n",
      "\t[3,   100] G loss: 0.310141228\n",
      "\t[3,   200] G loss: 0.309947436\n",
      "Currently running epoch Nbr 3\n",
      "\t[1,   100] D loss: 0.338649715\n",
      "\t[1,   200] D loss: 0.305576634\n",
      "\t[2,   100] D loss: 0.264161235\n",
      "\t[2,   200] D loss: 0.242071131\n",
      "\t[3,   100] D loss: 0.210044224\n",
      "\t[3,   200] D loss: 0.193618531\n",
      "\t\t Running 3th iteration on G\n",
      "\t[3,   100] G loss: 0.160507095\n",
      "\t[3,   200] G loss: 0.160356241\n",
      "Currently running epoch Nbr 4\n",
      "\t[1,   100] D loss: 0.170361646\n",
      "\t[1,   200] D loss: 0.157236832\n",
      "\t[2,   100] D loss: 0.139873981\n",
      "\t[2,   200] D loss: 0.129206294\n",
      "\t[3,   100] D loss: 0.116013982\n",
      "\t[3,   200] D loss: 0.108708176\n",
      "\t\t Running 4th iteration on G\n",
      "\t[3,   100] G loss: 0.091435516\n",
      "\t[3,   200] G loss: 0.091334089\n",
      "Currently running epoch Nbr 5\n",
      "\t[1,   100] D loss: 0.097862723\n",
      "\t[1,   200] D loss: 0.091608534\n",
      "\t[2,   100] D loss: 0.083092825\n",
      "\t[2,   200] D loss: 0.078262678\n",
      "\t[3,   100] D loss: 0.071823279\n",
      "\t[3,   200] D loss: 0.067710714\n",
      "\t\t Running 5th iteration on G\n",
      "\t[3,   100] G loss: 0.057692373\n",
      "\t[3,   200] G loss: 0.057626751\n",
      "Currently running epoch Nbr 6\n",
      "\t[1,   100] D loss: 0.062065025\n",
      "\t[1,   200] D loss: 0.059253367\n",
      "\t[2,   100] D loss: 0.055113435\n",
      "\t[2,   200] D loss: 0.051886074\n",
      "\t[3,   100] D loss: 0.048477139\n",
      "\t[3,   200] D loss: 0.046332595\n",
      "\t\t Running 6th iteration on G\n",
      "\t[3,   100] G loss: 0.039570135\n",
      "\t[3,   200] G loss: 0.039529581\n",
      "Currently running epoch Nbr 7\n",
      "\t[1,   100] D loss: 0.042686490\n",
      "\t[1,   200] D loss: 0.041418394\n",
      "\t[2,   100] D loss: 0.038951299\n",
      "\t[2,   200] D loss: 0.037141589\n",
      "\t[3,   100] D loss: 0.035332344\n",
      "\t[3,   200] D loss: 0.033678823\n",
      "\t\t Running 7th iteration on G\n",
      "\t[3,   100] G loss: 0.028872762\n",
      "\t[3,   200] G loss: 0.028847369\n",
      "Currently running epoch Nbr 8\n",
      "\t[1,   100] D loss: 0.031925908\n",
      "\t[1,   200] D loss: 0.030704260\n",
      "\t[2,   100] D loss: 0.028977194\n",
      "\t[2,   200] D loss: 0.028069018\n",
      "\t[3,   100] D loss: 0.026745321\n",
      "\t[3,   200] D loss: 0.025580106\n",
      "\t\t Running 8th iteration on G\n",
      "\t[3,   100] G loss: 0.022085290\n",
      "\t[3,   200] G loss: 0.022059871\n",
      "Currently running epoch Nbr 9\n",
      "\t[1,   100] D loss: 0.024730554\n",
      "\t[1,   200] D loss: 0.023691534\n",
      "\t[2,   100] D loss: 0.022530913\n",
      "\t[2,   200] D loss: 0.021953571\n",
      "\t[3,   100] D loss: 0.021235967\n",
      "\t[3,   200] D loss: 0.020452547\n",
      "\t\t Running 9th iteration on G\n",
      "\t[3,   100] G loss: 0.017507244\n",
      "\t[3,   200] G loss: 0.017485130\n",
      "Currently running epoch Nbr 10\n",
      "\t[1,   100] D loss: 0.019806031\n",
      "\t[1,   200] D loss: 0.018996912\n",
      "\t[2,   100] D loss: 0.018178233\n",
      "\t[2,   200] D loss: 0.017625618\n",
      "\t[3,   100] D loss: 0.017118014\n",
      "\t[3,   200] D loss: 0.016644687\n",
      "\t\t Running 10th iteration on G\n",
      "\t[3,   100] G loss: 0.014278048\n",
      "\t[3,   200] G loss: 0.014263243\n",
      "Currently running epoch Nbr 11\n",
      "\t[1,   100] D loss: 0.015929776\n",
      "\t[1,   200] D loss: 0.015668352\n",
      "\t[2,   100] D loss: 0.014861043\n",
      "\t[2,   200] D loss: 0.014936426\n",
      "\t[3,   100] D loss: 0.014071981\n",
      "\t[3,   200] D loss: 0.014159616\n",
      "\t\t Running 11th iteration on G\n",
      "\t[3,   100] G loss: 0.011906489\n",
      "\t[3,   200] G loss: 0.011892957\n",
      "Currently running epoch Nbr 12\n",
      "\t[1,   100] D loss: 0.013700897\n",
      "\t[1,   200] D loss: 0.012915008\n",
      "\t[2,   100] D loss: 0.013010064\n",
      "\t[2,   200] D loss: 0.012475698\n",
      "\t[3,   100] D loss: 0.011987862\n",
      "\t[3,   200] D loss: 0.011874534\n",
      "\t\t Running 12th iteration on G\n",
      "\t[3,   100] G loss: 0.010110906\n",
      "\t[3,   200] G loss: 0.010098943\n",
      "Currently running epoch Nbr 13\n",
      "\t[1,   100] D loss: 0.011725430\n",
      "\t[1,   200] D loss: 0.011258371\n",
      "\t[2,   100] D loss: 0.010815810\n",
      "\t[2,   200] D loss: 0.010720804\n",
      "\t[3,   100] D loss: 0.010520522\n",
      "\t[3,   200] D loss: 0.010213658\n",
      "\t\t Running 13th iteration on G\n",
      "\t[3,   100] G loss: 0.008720808\n",
      "\t[3,   200] G loss: 0.008709681\n",
      "Currently running epoch Nbr 14\n",
      "\t[1,   100] D loss: 0.010039692\n",
      "\t[1,   200] D loss: 0.009593250\n",
      "\t[2,   100] D loss: 0.009701678\n",
      "\t[2,   200] D loss: 0.009374996\n",
      "\t[3,   100] D loss: 0.009038244\n",
      "\t[3,   200] D loss: 0.008977106\n",
      "\t\t Running 14th iteration on G\n",
      "\t[3,   100] G loss: 0.007616390\n",
      "\t[3,   200] G loss: 0.007605275\n",
      "Currently running epoch Nbr 15\n",
      "\t[1,   100] D loss: 0.008832939\n",
      "\t[1,   200] D loss: 0.008529872\n",
      "\t[2,   100] D loss: 0.008228331\n",
      "\t[2,   200] D loss: 0.008354695\n",
      "\t[3,   100] D loss: 0.007853261\n",
      "\t[3,   200] D loss: 0.008195213\n",
      "\t\t Running 15th iteration on G\n",
      "\t[3,   100] G loss: 0.006721361\n",
      "\t[3,   200] G loss: 0.006716628\n",
      "Currently running epoch Nbr 16\n",
      "\t[1,   100] D loss: 0.007810423\n",
      "\t[1,   200] D loss: 0.007641901\n",
      "\t[2,   100] D loss: 0.007394426\n",
      "\t[2,   200] D loss: 0.007298822\n",
      "\t[3,   100] D loss: 0.007277472\n",
      "\t[3,   200] D loss: 0.006985023\n",
      "\t\t Running 16th iteration on G\n",
      "\t[3,   100] G loss: 0.005991029\n",
      "\t[3,   200] G loss: 0.005985100\n",
      "Currently running epoch Nbr 17\n",
      "\t[1,   100] D loss: 0.006931187\n",
      "\t[1,   200] D loss: 0.006670321\n",
      "\t[2,   100] D loss: 0.006933248\n",
      "\t[2,   200] D loss: 0.006453881\n",
      "\t[3,   100] D loss: 0.006387021\n",
      "\t[3,   200] D loss: 0.006292531\n",
      "\t\t Running 17th iteration on G\n",
      "\t[3,   100] G loss: 0.005381918\n",
      "\t[3,   200] G loss: 0.005376010\n",
      "Currently running epoch Nbr 18\n",
      "\t[1,   100] D loss: 0.006384714\n",
      "\t[1,   200] D loss: 0.006017314\n",
      "\t[2,   100] D loss: 0.006207903\n",
      "\t[2,   200] D loss: 0.005869382\n",
      "\t[3,   100] D loss: 0.005834805\n",
      "\t[3,   200] D loss: 0.005860086\n",
      "\t\t Running 18th iteration on G\n",
      "\t[3,   100] G loss: 0.004865535\n",
      "\t[3,   200] G loss: 0.004864088\n",
      "Currently running epoch Nbr 19\n",
      "\t[1,   100] D loss: 0.005552628\n",
      "\t[1,   200] D loss: 0.005679863\n",
      "\t[2,   100] D loss: 0.005500004\n",
      "\t[2,   200] D loss: 0.005511609\n",
      "\t[3,   100] D loss: 0.005440627\n",
      "\t[3,   200] D loss: 0.005061360\n",
      "\t\t Running 19th iteration on G\n",
      "\t[3,   100] G loss: 0.004431952\n",
      "\t[3,   200] G loss: 0.004427851\n",
      "Currently running epoch Nbr 20\n",
      "\t[1,   100] D loss: 0.005148614\n",
      "\t[1,   200] D loss: 0.005133368\n",
      "\t[2,   100] D loss: 0.004917542\n",
      "\t[2,   200] D loss: 0.004982423\n",
      "\t[3,   100] D loss: 0.004757876\n",
      "\t[3,   200] D loss: 0.004966153\n",
      "\t\t Running 20th iteration on G\n",
      "\t[3,   100] G loss: 0.004055412\n",
      "\t[3,   200] G loss: 0.004052620\n",
      "Currently running epoch Nbr 21\n",
      "\t[1,   100] D loss: 0.004830761\n",
      "\t[1,   200] D loss: 0.004736243\n",
      "\t[2,   100] D loss: 0.004740400\n",
      "\t[2,   200] D loss: 0.004490693\n",
      "\t[3,   100] D loss: 0.004570333\n",
      "\t[3,   200] D loss: 0.004313791\n",
      "\t\t Running 21th iteration on G\n",
      "\t[3,   100] G loss: 0.003731911\n",
      "\t[3,   200] G loss: 0.003731290\n",
      "Currently running epoch Nbr 22\n",
      "\t[1,   100] D loss: 0.004294439\n",
      "\t[1,   200] D loss: 0.004390524\n",
      "\t[2,   100] D loss: 0.004103770\n",
      "\t[2,   200] D loss: 0.004214460\n",
      "\t[3,   100] D loss: 0.004138528\n",
      "\t[3,   200] D loss: 0.004096806\n",
      "\t\t Running 22th iteration on G\n",
      "\t[3,   100] G loss: 0.003449141\n",
      "\t[3,   200] G loss: 0.003445247\n",
      "Currently running epoch Nbr 23\n",
      "\t[1,   100] D loss: 0.003990504\n",
      "\t[1,   200] D loss: 0.003942102\n",
      "\t[2,   100] D loss: 0.003952623\n",
      "\t[2,   200] D loss: 0.003845320\n",
      "\t[3,   100] D loss: 0.004018197\n",
      "\t[3,   200] D loss: 0.003732291\n",
      "\t\t Running 23th iteration on G\n",
      "\t[3,   100] G loss: 0.003197434\n",
      "\t[3,   200] G loss: 0.003198401\n",
      "Currently running epoch Nbr 24\n",
      "\t[1,   100] D loss: 0.003775996\n",
      "\t[1,   200] D loss: 0.003648732\n",
      "\t[2,   100] D loss: 0.003667912\n",
      "\t[2,   200] D loss: 0.003665355\n",
      "\t[3,   100] D loss: 0.003773876\n",
      "\t[3,   200] D loss: 0.003433466\n",
      "\t\t Running 24th iteration on G\n",
      "\t[3,   100] G loss: 0.002979401\n",
      "\t[3,   200] G loss: 0.002975649\n",
      "Currently running epoch Nbr 25\n",
      "\t[1,   100] D loss: 0.003629192\n",
      "\t[1,   200] D loss: 0.003327230\n",
      "\t[2,   100] D loss: 0.003319188\n",
      "\t[2,   200] D loss: 0.003507489\n",
      "\t[3,   100] D loss: 0.003488941\n",
      "\t[3,   200] D loss: 0.003242262\n",
      "\t\t Running 25th iteration on G\n",
      "\t[3,   100] G loss: 0.002781466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[3,   200] G loss: 0.002781700\n",
      "Currently running epoch Nbr 26\n",
      "\t[1,   100] D loss: 0.003387081\n",
      "\t[1,   200] D loss: 0.003196521\n",
      "\t[2,   100] D loss: 0.003226969\n",
      "\t[2,   200] D loss: 0.003031319\n",
      "\t[3,   100] D loss: 0.003306158\n",
      "\t[3,   200] D loss: 0.003087214\n",
      "\t\t Running 26th iteration on G\n",
      "\t[3,   100] G loss: 0.002609076\n",
      "\t[3,   200] G loss: 0.002606111\n",
      "Currently running epoch Nbr 27\n",
      "\t[1,   100] D loss: 0.002981663\n",
      "\t[1,   200] D loss: 0.003184664\n",
      "\t[2,   100] D loss: 0.002999419\n",
      "\t[2,   200] D loss: 0.003039499\n",
      "\t[3,   100] D loss: 0.002913310\n",
      "\t[3,   200] D loss: 0.002846684\n",
      "\t\t Running 27th iteration on G\n",
      "\t[3,   100] G loss: 0.002454201\n",
      "\t[3,   200] G loss: 0.002450064\n",
      "Currently running epoch Nbr 28\n",
      "\t[1,   100] D loss: 0.003070909\n",
      "\t[1,   200] D loss: 0.002782695\n",
      "\t[2,   100] D loss: 0.002818718\n",
      "\t[2,   200] D loss: 0.002888303\n",
      "\t[3,   100] D loss: 0.002814068\n",
      "\t[3,   200] D loss: 0.002839642\n",
      "\t\t Running 28th iteration on G\n",
      "\t[3,   100] G loss: 0.002309068\n",
      "\t[3,   200] G loss: 0.002308474\n",
      "Currently running epoch Nbr 29\n",
      "\t[1,   100] D loss: 0.002778796\n",
      "\t[1,   200] D loss: 0.002756368\n",
      "\t[2,   100] D loss: 0.002621472\n",
      "\t[2,   200] D loss: 0.002784545\n",
      "\t[3,   100] D loss: 0.002599029\n",
      "\t[3,   200] D loss: 0.002715252\n",
      "\t\t Running 29th iteration on G\n",
      "\t[3,   100] G loss: 0.002180415\n",
      "\t[3,   200] G loss: 0.002179144\n",
      "Currently running epoch Nbr 30\n",
      "\t[1,   100] D loss: 0.002643131\n",
      "\t[1,   200] D loss: 0.002546837\n",
      "\t[2,   100] D loss: 0.002502338\n",
      "\t[2,   200] D loss: 0.002558096\n",
      "\t[3,   100] D loss: 0.002618602\n",
      "\t[3,   200] D loss: 0.002450003\n",
      "\t\t Running 30th iteration on G\n",
      "\t[3,   100] G loss: 0.002064642\n",
      "\t[3,   200] G loss: 0.002064429\n",
      "Currently running epoch Nbr 31\n",
      "\t[1,   100] D loss: 0.002433326\n",
      "\t[1,   200] D loss: 0.002464677\n",
      "\t[2,   100] D loss: 0.002458972\n",
      "\t[2,   200] D loss: 0.002423533\n",
      "\t[3,   100] D loss: 0.002445860\n",
      "\t[3,   200] D loss: 0.002298482\n",
      "\t\t Running 31th iteration on G\n",
      "\t[3,   100] G loss: 0.001958815\n",
      "\t[3,   200] G loss: 0.001956302\n",
      "Currently running epoch Nbr 32\n",
      "\t[1,   100] D loss: 0.002400857\n",
      "\t[1,   200] D loss: 0.002269464\n",
      "\t[2,   100] D loss: 0.002327344\n",
      "\t[2,   200] D loss: 0.002325971\n",
      "\t[3,   100] D loss: 0.002162228\n",
      "\t[3,   200] D loss: 0.002308838\n",
      "\t\t Running 32th iteration on G\n",
      "\t[3,   100] G loss: 0.001859999\n",
      "\t[3,   200] G loss: 0.001859557\n",
      "Currently running epoch Nbr 33\n",
      "\t[1,   100] D loss: 0.002206034\n",
      "\t[1,   200] D loss: 0.002142883\n",
      "\t[2,   100] D loss: 0.002154166\n",
      "\t[2,   200] D loss: 0.002128459\n",
      "\t[3,   100] D loss: 0.002152195\n",
      "\t[3,   200] D loss: 0.002083899\n",
      "\t\t Running 33th iteration on G\n",
      "\t[3,   100] G loss: 0.001770061\n",
      "\t[3,   200] G loss: 0.001769548\n",
      "Currently running epoch Nbr 34\n",
      "\t[1,   100] D loss: 0.002075592\n",
      "\t[1,   200] D loss: 0.002129572\n",
      "\t[2,   100] D loss: 0.002108094\n",
      "\t[2,   200] D loss: 0.002120284\n",
      "\t[3,   100] D loss: 0.002022782\n",
      "\t[3,   200] D loss: 0.002043267\n",
      "\t\t Running 34th iteration on G\n",
      "\t[3,   100] G loss: 0.001687661\n",
      "\t[3,   200] G loss: 0.001687272\n",
      "Currently running epoch Nbr 35\n",
      "\t[1,   100] D loss: 0.001992682\n",
      "\t[1,   200] D loss: 0.002036272\n",
      "\t[2,   100] D loss: 0.002047753\n",
      "\t[2,   200] D loss: 0.001862783\n",
      "\t[3,   100] D loss: 0.001983196\n",
      "\t[3,   200] D loss: 0.001954153\n",
      "\t\t Running 35th iteration on G\n",
      "\t[3,   100] G loss: 0.001610570\n",
      "\t[3,   200] G loss: 0.001611209\n",
      "Currently running epoch Nbr 36\n",
      "\t[1,   100] D loss: 0.001861997\n",
      "\t[1,   200] D loss: 0.001983435\n",
      "\t[2,   100] D loss: 0.001825713\n",
      "\t[2,   200] D loss: 0.001970635\n",
      "\t[3,   100] D loss: 0.001945684\n",
      "\t[3,   200] D loss: 0.001841643\n",
      "\t\t Running 36th iteration on G\n",
      "\t[3,   100] G loss: 0.001541803\n",
      "\t[3,   200] G loss: 0.001539968\n",
      "Currently running epoch Nbr 37\n",
      "\t[1,   100] D loss: 0.001784159\n",
      "\t[1,   200] D loss: 0.001837610\n",
      "\t[2,   100] D loss: 0.001749434\n",
      "\t[2,   200] D loss: 0.001872407\n",
      "\t[3,   100] D loss: 0.001730744\n",
      "\t[3,   200] D loss: 0.001882567\n",
      "\t\t Running 37th iteration on G\n",
      "\t[3,   100] G loss: 0.001475426\n",
      "\t[3,   200] G loss: 0.001474487\n",
      "Currently running epoch Nbr 38\n",
      "\t[1,   100] D loss: 0.001691010\n",
      "\t[1,   200] D loss: 0.001859193\n",
      "\t[2,   100] D loss: 0.001695096\n",
      "\t[2,   200] D loss: 0.001743743\n",
      "\t[3,   100] D loss: 0.001733386\n",
      "\t[3,   200] D loss: 0.001708669\n",
      "\t\t Running 38th iteration on G\n",
      "\t[3,   100] G loss: 0.001414617\n",
      "\t[3,   200] G loss: 0.001414564\n",
      "Currently running epoch Nbr 39\n",
      "\t[1,   100] D loss: 0.001643085\n",
      "\t[1,   200] D loss: 0.001701597\n",
      "\t[2,   100] D loss: 0.001755220\n",
      "\t[2,   200] D loss: 0.001584165\n",
      "\t[3,   100] D loss: 0.001669891\n",
      "\t[3,   200] D loss: 0.001657668\n",
      "\t\t Running 39th iteration on G\n",
      "\t[3,   100] G loss: 0.001358869\n",
      "\t[3,   200] G loss: 0.001358079\n",
      "Currently running epoch Nbr 40\n",
      "\t[1,   100] D loss: 0.001631301\n",
      "\t[1,   200] D loss: 0.001525518\n",
      "\t[2,   100] D loss: 0.001698101\n",
      "\t[2,   200] D loss: 0.001509241\n",
      "\t[3,   100] D loss: 0.001579748\n",
      "\t[3,   200] D loss: 0.001655073\n",
      "\t\t Running 40th iteration on G\n",
      "\t[3,   100] G loss: 0.001305804\n",
      "\t[3,   200] G loss: 0.001305363\n",
      "Currently running epoch Nbr 41\n",
      "\t[1,   100] D loss: 0.001525272\n",
      "\t[1,   200] D loss: 0.001550532\n",
      "\t[2,   100] D loss: 0.001666841\n",
      "\t[2,   200] D loss: 0.001429334\n",
      "\t[3,   100] D loss: 0.001497930\n",
      "\t[3,   200] D loss: 0.001491459\n",
      "\t\t Running 41th iteration on G\n",
      "\t[3,   100] G loss: 0.001255922\n",
      "\t[3,   200] G loss: 0.001255711\n",
      "Currently running epoch Nbr 42\n",
      "\t[1,   100] D loss: 0.001535700\n",
      "\t[1,   200] D loss: 0.001456753\n",
      "\t[2,   100] D loss: 0.001457283\n",
      "\t[2,   200] D loss: 0.001490005\n",
      "\t[3,   100] D loss: 0.001429859\n",
      "\t[3,   200] D loss: 0.001499904\n",
      "\t\t Running 42th iteration on G\n",
      "\t[3,   100] G loss: 0.001210743\n",
      "\t[3,   200] G loss: 0.001210607\n",
      "Currently running epoch Nbr 43\n",
      "\t[1,   100] D loss: 0.001411371\n",
      "\t[1,   200] D loss: 0.001436825\n",
      "\t[2,   100] D loss: 0.001393623\n",
      "\t[2,   200] D loss: 0.001483954\n",
      "\t[3,   100] D loss: 0.001440954\n",
      "\t[3,   200] D loss: 0.001460360\n",
      "\t\t Running 43th iteration on G\n",
      "\t[3,   100] G loss: 0.001165223\n",
      "\t[3,   200] G loss: 0.001166548\n",
      "Currently running epoch Nbr 44\n",
      "\t[1,   100] D loss: 0.001513421\n",
      "\t[1,   200] D loss: 0.001324653\n",
      "\t[2,   100] D loss: 0.001378207\n",
      "\t[2,   200] D loss: 0.001415877\n",
      "\t[3,   100] D loss: 0.001333912\n",
      "\t[3,   200] D loss: 0.001401279\n",
      "\t\t Running 44th iteration on G\n",
      "\t[3,   100] G loss: 0.001125987\n",
      "\t[3,   200] G loss: 0.001125887\n",
      "Currently running epoch Nbr 45\n",
      "\t[1,   100] D loss: 0.001365545\n",
      "\t[1,   200] D loss: 0.001355834\n",
      "\t[2,   100] D loss: 0.001242838\n",
      "\t[2,   200] D loss: 0.001310800\n",
      "\t[3,   100] D loss: 0.001420143\n",
      "\t[3,   200] D loss: 0.001250840\n",
      "\t\t Running 45th iteration on G\n",
      "\t[3,   100] G loss: 0.001087752\n",
      "\t[3,   200] G loss: 0.001086839\n",
      "Currently running epoch Nbr 46\n",
      "\t[1,   100] D loss: 0.001288824\n",
      "\t[1,   200] D loss: 0.001349660\n",
      "\t[2,   100] D loss: 0.001281803\n",
      "\t[2,   200] D loss: 0.001321922\n",
      "\t[3,   100] D loss: 0.001243276\n",
      "\t[3,   200] D loss: 0.001318211\n",
      "\t\t Running 46th iteration on G\n",
      "\t[3,   100] G loss: 0.001050445\n",
      "\t[3,   200] G loss: 0.001051925\n",
      "Currently running epoch Nbr 47\n",
      "\t[1,   100] D loss: 0.001257080\n",
      "\t[1,   200] D loss: 0.001303149\n",
      "\t[2,   100] D loss: 0.001281938\n",
      "\t[2,   200] D loss: 0.001173395\n",
      "\t[3,   100] D loss: 0.001241929\n",
      "\t[3,   200] D loss: 0.001229565\n",
      "\t\t Running 47th iteration on G\n",
      "\t[3,   100] G loss: 0.001016742\n",
      "\t[3,   200] G loss: 0.001016633\n",
      "Currently running epoch Nbr 48\n",
      "\t[1,   100] D loss: 0.001287067\n",
      "\t[1,   200] D loss: 0.001210749\n",
      "\t[2,   100] D loss: 0.001187688\n",
      "\t[2,   200] D loss: 0.001199198\n",
      "\t[3,   100] D loss: 0.001160533\n",
      "\t[3,   200] D loss: 0.001249465\n",
      "\t\t Running 48th iteration on G\n",
      "\t[3,   100] G loss: 0.000983868\n",
      "\t[3,   200] G loss: 0.000984037\n",
      "Currently running epoch Nbr 49\n",
      "\t[1,   100] D loss: 0.001200035\n",
      "\t[1,   200] D loss: 0.001213873\n",
      "\t[2,   100] D loss: 0.001182292\n",
      "\t[2,   200] D loss: 0.001199286\n",
      "\t[3,   100] D loss: 0.001171792\n",
      "\t[3,   200] D loss: 0.001179160\n",
      "\t\t Running 49th iteration on G\n",
      "\t[3,   100] G loss: 0.000953809\n",
      "\t[3,   200] G loss: 0.000953383\n",
      "Currently running epoch Nbr 50\n",
      "\t[1,   100] D loss: 0.001145370\n",
      "\t[1,   200] D loss: 0.001179421\n",
      "\t[2,   100] D loss: 0.001165038\n",
      "\t[2,   200] D loss: 0.001089821\n",
      "\t[3,   100] D loss: 0.001122776\n",
      "\t[3,   200] D loss: 0.001183533\n",
      "\t\t Running 50th iteration on G\n",
      "\t[3,   100] G loss: 0.000924910\n",
      "\t[3,   200] G loss: 0.000924740\n",
      "Currently running epoch Nbr 51\n",
      "\t[1,   100] D loss: 0.001073062\n",
      "\t[1,   200] D loss: 0.001183574\n",
      "\t[2,   100] D loss: 0.001100288\n",
      "\t[2,   200] D loss: 0.001091745\n",
      "\t[3,   100] D loss: 0.001122336\n",
      "\t[3,   200] D loss: 0.001086917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Running 51th iteration on G\n",
      "\t[3,   100] G loss: 0.000897439\n",
      "\t[3,   200] G loss: 0.000896789\n",
      "Currently running epoch Nbr 52\n",
      "\t[1,   100] D loss: 0.001071276\n",
      "\t[1,   200] D loss: 0.001080331\n",
      "\t[2,   100] D loss: 0.001094623\n",
      "\t[2,   200] D loss: 0.001054077\n",
      "\t[3,   100] D loss: 0.001082644\n",
      "\t[3,   200] D loss: 0.001075710\n",
      "\t\t Running 52th iteration on G\n",
      "\t[3,   100] G loss: 0.000870959\n",
      "\t[3,   200] G loss: 0.000871235\n",
      "Currently running epoch Nbr 53\n",
      "\t[1,   100] D loss: 0.001075107\n",
      "\t[1,   200] D loss: 0.001016324\n",
      "\t[2,   100] D loss: 0.001065020\n",
      "\t[2,   200] D loss: 0.001042593\n",
      "\t[3,   100] D loss: 0.001089802\n",
      "\t[3,   200] D loss: 0.000988913\n",
      "\t\t Running 53th iteration on G\n",
      "\t[3,   100] G loss: 0.000845894\n",
      "\t[3,   200] G loss: 0.000846125\n",
      "Currently running epoch Nbr 54\n",
      "\t[1,   100] D loss: 0.001030180\n",
      "\t[1,   200] D loss: 0.001034807\n",
      "\t[2,   100] D loss: 0.001054046\n",
      "\t[2,   200] D loss: 0.001009253\n",
      "\t[3,   100] D loss: 0.000962289\n",
      "\t[3,   200] D loss: 0.001073407\n",
      "\t\t Running 54th iteration on G\n",
      "\t[3,   100] G loss: 0.000822575\n",
      "\t[3,   200] G loss: 0.000821357\n",
      "Currently running epoch Nbr 55\n",
      "\t[1,   100] D loss: 0.000982901\n",
      "\t[1,   200] D loss: 0.001034792\n",
      "\t[2,   100] D loss: 0.000933099\n",
      "\t[2,   200] D loss: 0.001034926\n",
      "\t[3,   100] D loss: 0.000959104\n",
      "\t[3,   200] D loss: 0.001005605\n",
      "\t\t Running 55th iteration on G\n",
      "\t[3,   100] G loss: 0.000799811\n",
      "\t[3,   200] G loss: 0.000799763\n",
      "Currently running epoch Nbr 56\n",
      "\t[1,   100] D loss: 0.000980238\n",
      "\t[1,   200] D loss: 0.000937755\n",
      "\t[2,   100] D loss: 0.000930230\n",
      "\t[2,   200] D loss: 0.000964678\n",
      "\t[3,   100] D loss: 0.000963593\n",
      "\t[3,   200] D loss: 0.000968475\n",
      "\t\t Running 56th iteration on G\n",
      "\t[3,   100] G loss: 0.000778802\n",
      "\t[3,   200] G loss: 0.000778214\n",
      "Currently running epoch Nbr 57\n",
      "\t[1,   100] D loss: 0.000929195\n",
      "\t[1,   200] D loss: 0.000938038\n",
      "\t[2,   100] D loss: 0.000974046\n",
      "\t[2,   200] D loss: 0.000919493\n",
      "\t[3,   100] D loss: 0.000916567\n",
      "\t[3,   200] D loss: 0.000892088\n",
      "\t\t Running 57th iteration on G\n",
      "\t[3,   100] G loss: 0.000758312\n",
      "\t[3,   200] G loss: 0.000757924\n",
      "Currently running epoch Nbr 58\n",
      "\t[1,   100] D loss: 0.000885893\n",
      "\t[1,   200] D loss: 0.000939445\n",
      "\t[2,   100] D loss: 0.000924556\n",
      "\t[2,   200] D loss: 0.000901941\n",
      "\t[3,   100] D loss: 0.000947177\n",
      "\t[3,   200] D loss: 0.000896202\n",
      "\t\t Running 58th iteration on G\n",
      "\t[3,   100] G loss: 0.000737978\n",
      "\t[3,   200] G loss: 0.000737546\n",
      "Currently running epoch Nbr 59\n",
      "\t[1,   100] D loss: 0.000905074\n",
      "\t[1,   200] D loss: 0.000875824\n",
      "\t[2,   100] D loss: 0.000949763\n",
      "\t[2,   200] D loss: 0.000866971\n",
      "\t[3,   100] D loss: 0.000874970\n",
      "\t[3,   200] D loss: 0.000851949\n",
      "\t\t Running 59th iteration on G\n",
      "\t[3,   100] G loss: 0.000719253\n",
      "\t[3,   200] G loss: 0.000719837\n",
      "Currently running epoch Nbr 60\n",
      "\t[1,   100] D loss: 0.000898754\n",
      "\t[1,   200] D loss: 0.000853787\n",
      "\t[2,   100] D loss: 0.000887164\n",
      "\t[2,   200] D loss: 0.000880288\n",
      "\t[3,   100] D loss: 0.000858090\n",
      "\t[3,   200] D loss: 0.000884752\n",
      "\t\t Running 60th iteration on G\n",
      "\t[3,   100] G loss: 0.000702457\n",
      "\t[3,   200] G loss: 0.000701788\n",
      "Currently running epoch Nbr 61\n",
      "\t[1,   100] D loss: 0.000847127\n",
      "\t[1,   200] D loss: 0.000820261\n",
      "\t[2,   100] D loss: 0.000847008\n",
      "\t[2,   200] D loss: 0.000862988\n",
      "\t[3,   100] D loss: 0.000838723\n",
      "\t[3,   200] D loss: 0.000869330\n",
      "\t\t Running 61th iteration on G\n",
      "\t[3,   100] G loss: 0.000684150\n",
      "\t[3,   200] G loss: 0.000684340\n",
      "Currently running epoch Nbr 62\n",
      "\t[1,   100] D loss: 0.000811178\n",
      "\t[1,   200] D loss: 0.000842291\n",
      "\t[2,   100] D loss: 0.000836888\n",
      "\t[2,   200] D loss: 0.000805728\n",
      "\t[3,   100] D loss: 0.000807056\n",
      "\t[3,   200] D loss: 0.000854323\n",
      "\t\t Running 62th iteration on G\n",
      "\t[3,   100] G loss: 0.000668366\n",
      "\t[3,   200] G loss: 0.000667957\n",
      "Currently running epoch Nbr 63\n",
      "\t[1,   100] D loss: 0.000793529\n",
      "\t[1,   200] D loss: 0.000838905\n",
      "\t[2,   100] D loss: 0.000814447\n",
      "\t[2,   200] D loss: 0.000845702\n",
      "\t[3,   100] D loss: 0.000774823\n",
      "\t[3,   200] D loss: 0.000820699\n",
      "\t\t Running 63th iteration on G\n",
      "\t[3,   100] G loss: 0.000652706\n",
      "\t[3,   200] G loss: 0.000652013\n",
      "Currently running epoch Nbr 64\n",
      "\t[1,   100] D loss: 0.000746788\n",
      "\t[1,   200] D loss: 0.000824658\n",
      "\t[2,   100] D loss: 0.000766539\n",
      "\t[2,   200] D loss: 0.000769021\n",
      "\t[3,   100] D loss: 0.000773425\n",
      "\t[3,   200] D loss: 0.000783567\n",
      "\t\t Running 64th iteration on G\n",
      "\t[3,   100] G loss: 0.000637046\n",
      "\t[3,   200] G loss: 0.000636625\n",
      "Currently running epoch Nbr 65\n",
      "\t[1,   100] D loss: 0.000801078\n",
      "\t[1,   200] D loss: 0.000718317\n",
      "\t[2,   100] D loss: 0.000801826\n",
      "\t[2,   200] D loss: 0.000750737\n",
      "\t[3,   100] D loss: 0.000782263\n",
      "\t[3,   200] D loss: 0.000718775\n",
      "\t\t Running 65th iteration on G\n",
      "\t[3,   100] G loss: 0.000621972\n",
      "\t[3,   200] G loss: 0.000622630\n",
      "Currently running epoch Nbr 66\n",
      "\t[1,   100] D loss: 0.000789492\n",
      "\t[1,   200] D loss: 0.000742546\n",
      "\t[2,   100] D loss: 0.000752661\n",
      "\t[2,   200] D loss: 0.000758380\n",
      "\t[3,   100] D loss: 0.000736680\n",
      "\t[3,   200] D loss: 0.000792372\n",
      "\t\t Running 66th iteration on G\n",
      "\t[3,   100] G loss: 0.000609325\n",
      "\t[3,   200] G loss: 0.000608610\n",
      "Currently running epoch Nbr 67\n",
      "\t[1,   100] D loss: 0.000765180\n",
      "\t[1,   200] D loss: 0.000716317\n",
      "\t[2,   100] D loss: 0.000703634\n",
      "\t[2,   200] D loss: 0.000766794\n",
      "\t[3,   100] D loss: 0.000785683\n",
      "\t[3,   200] D loss: 0.000706025\n",
      "\t\t Running 67th iteration on G\n",
      "\t[3,   100] G loss: 0.000594623\n",
      "\t[3,   200] G loss: 0.000594944\n",
      "Currently running epoch Nbr 68\n",
      "\t[1,   100] D loss: 0.000722060\n",
      "\t[1,   200] D loss: 0.000752332\n",
      "\t[2,   100] D loss: 0.000744568\n",
      "\t[2,   200] D loss: 0.000690356\n",
      "\t[3,   100] D loss: 0.000779874\n",
      "\t[3,   200] D loss: 0.000668493\n",
      "\t\t Running 68th iteration on G\n",
      "\t[3,   100] G loss: 0.000582706\n",
      "\t[3,   200] G loss: 0.000582408\n",
      "Currently running epoch Nbr 69\n",
      "\t[1,   100] D loss: 0.000714104\n",
      "\t[1,   200] D loss: 0.000677145\n",
      "\t[2,   100] D loss: 0.000677579\n",
      "\t[2,   200] D loss: 0.000731511\n",
      "\t[3,   100] D loss: 0.000679687\n",
      "\t[3,   200] D loss: 0.000709349\n",
      "\t\t Running 69th iteration on G\n",
      "\t[3,   100] G loss: 0.000569651\n",
      "\t[3,   200] G loss: 0.000569540\n",
      "Currently running epoch Nbr 70\n",
      "\t[1,   100] D loss: 0.000709994\n",
      "\t[1,   200] D loss: 0.000679894\n",
      "\t[2,   100] D loss: 0.000702912\n",
      "\t[2,   200] D loss: 0.000680997\n",
      "\t[3,   100] D loss: 0.000671841\n",
      "\t[3,   200] D loss: 0.000674127\n",
      "\t\t Running 70th iteration on G\n",
      "\t[3,   100] G loss: 0.000557690\n",
      "\t[3,   200] G loss: 0.000557317\n",
      "Currently running epoch Nbr 71\n",
      "\t[1,   100] D loss: 0.000639170\n",
      "\t[1,   200] D loss: 0.000685571\n",
      "\t[2,   100] D loss: 0.000688938\n",
      "\t[2,   200] D loss: 0.000682248\n",
      "\t[3,   100] D loss: 0.000688822\n",
      "\t[3,   200] D loss: 0.000651009\n",
      "\t\t Running 71th iteration on G\n",
      "\t[3,   100] G loss: 0.000545760\n",
      "\t[3,   200] G loss: 0.000546308\n",
      "Currently running epoch Nbr 72\n",
      "\t[1,   100] D loss: 0.000681279\n",
      "\t[1,   200] D loss: 0.000691108\n",
      "\t[2,   100] D loss: 0.000691035\n",
      "\t[2,   200] D loss: 0.000647738\n",
      "\t[3,   100] D loss: 0.000672703\n",
      "\t[3,   200] D loss: 0.000637708\n",
      "\t\t Running 72th iteration on G\n",
      "\t[3,   100] G loss: 0.000534619\n",
      "\t[3,   200] G loss: 0.000535461\n",
      "Currently running epoch Nbr 73\n",
      "\t[1,   100] D loss: 0.000684706\n",
      "\t[1,   200] D loss: 0.000647344\n",
      "\t[2,   100] D loss: 0.000669513\n",
      "\t[2,   200] D loss: 0.000647988\n",
      "\t[3,   100] D loss: 0.000682317\n",
      "\t[3,   200] D loss: 0.000639498\n",
      "\t\t Running 73th iteration on G\n",
      "\t[3,   100] G loss: 0.000524728\n",
      "\t[3,   200] G loss: 0.000524410\n",
      "Currently running epoch Nbr 74\n",
      "\t[1,   100] D loss: 0.000598474\n",
      "\t[1,   200] D loss: 0.000681937\n",
      "\t[2,   100] D loss: 0.000659566\n",
      "\t[2,   200] D loss: 0.000600421\n",
      "\t[3,   100] D loss: 0.000606590\n",
      "\t[3,   200] D loss: 0.000660766\n",
      "\t\t Running 74th iteration on G\n",
      "\t[3,   100] G loss: 0.000513505\n",
      "\t[3,   200] G loss: 0.000513902\n",
      "Currently running epoch Nbr 75\n",
      "\t[1,   100] D loss: 0.000645058\n",
      "\t[1,   200] D loss: 0.000634562\n",
      "\t[2,   100] D loss: 0.000636780\n",
      "\t[2,   200] D loss: 0.000595981\n",
      "\t[3,   100] D loss: 0.000608980\n",
      "\t[3,   200] D loss: 0.000615779\n",
      "\t\t Running 75th iteration on G\n",
      "\t[3,   100] G loss: 0.000503470\n",
      "\t[3,   200] G loss: 0.000503571\n",
      "Currently running epoch Nbr 76\n",
      "\t[1,   100] D loss: 0.000653679\n",
      "\t[1,   200] D loss: 0.000606337\n",
      "\t[2,   100] D loss: 0.000611832\n",
      "\t[2,   200] D loss: 0.000610604\n",
      "\t[3,   100] D loss: 0.000580302\n",
      "\t[3,   200] D loss: 0.000640748\n",
      "\t\t Running 76th iteration on G\n",
      "\t[3,   100] G loss: 0.000494173\n",
      "\t[3,   200] G loss: 0.000494249\n",
      "Currently running epoch Nbr 77\n",
      "\t[1,   100] D loss: 0.000604471\n",
      "\t[1,   200] D loss: 0.000609110\n",
      "\t[2,   100] D loss: 0.000584933\n",
      "\t[2,   200] D loss: 0.000651307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[3,   100] D loss: 0.000563510\n",
      "\t[3,   200] D loss: 0.000598584\n",
      "\t\t Running 77th iteration on G\n",
      "\t[3,   100] G loss: 0.000484974\n",
      "\t[3,   200] G loss: 0.000484358\n",
      "Currently running epoch Nbr 78\n",
      "\t[1,   100] D loss: 0.000626674\n",
      "\t[1,   200] D loss: 0.000560046\n",
      "\t[2,   100] D loss: 0.000624044\n",
      "\t[2,   200] D loss: 0.000587166\n",
      "\t[3,   100] D loss: 0.000556468\n",
      "\t[3,   200] D loss: 0.000588284\n",
      "\t\t Running 78th iteration on G\n",
      "\t[3,   100] G loss: 0.000475574\n",
      "\t[3,   200] G loss: 0.000475549\n",
      "Currently running epoch Nbr 79\n",
      "\t[1,   100] D loss: 0.000586209\n",
      "\t[1,   200] D loss: 0.000597816\n",
      "\t[2,   100] D loss: 0.000591270\n",
      "\t[2,   200] D loss: 0.000597974\n",
      "\t[3,   100] D loss: 0.000586568\n",
      "\t[3,   200] D loss: 0.000579046\n",
      "\t\t Running 79th iteration on G\n",
      "\t[3,   100] G loss: 0.000467670\n",
      "\t[3,   200] G loss: 0.000466811\n",
      "Currently running epoch Nbr 80\n",
      "\t[1,   100] D loss: 0.000572445\n",
      "\t[1,   200] D loss: 0.000579996\n",
      "\t[2,   100] D loss: 0.000577889\n",
      "\t[2,   200] D loss: 0.000582520\n",
      "\t[3,   100] D loss: 0.000552442\n",
      "\t[3,   200] D loss: 0.000586654\n",
      "\t\t Running 80th iteration on G\n",
      "\t[3,   100] G loss: 0.000457976\n",
      "\t[3,   200] G loss: 0.000458380\n",
      "Currently running epoch Nbr 81\n",
      "\t[1,   100] D loss: 0.000552249\n",
      "\t[1,   200] D loss: 0.000517926\n",
      "\t[2,   100] D loss: 0.000521772\n",
      "\t[2,   200] D loss: 0.000591206\n",
      "\t[3,   100] D loss: 0.000563032\n",
      "\t[3,   200] D loss: 0.000525535\n",
      "\t\t Running 81th iteration on G\n",
      "\t[3,   100] G loss: 0.000449880\n",
      "\t[3,   200] G loss: 0.000450138\n",
      "Currently running epoch Nbr 82\n",
      "\t[1,   100] D loss: 0.000556326\n",
      "\t[1,   200] D loss: 0.000571585\n",
      "\t[2,   100] D loss: 0.000514310\n",
      "\t[2,   200] D loss: 0.000546156\n",
      "\t[3,   100] D loss: 0.000577486\n",
      "\t[3,   200] D loss: 0.000543544\n",
      "\t\t Running 82th iteration on G\n",
      "\t[3,   100] G loss: 0.000440906\n",
      "\t[3,   200] G loss: 0.000441938\n",
      "Currently running epoch Nbr 83\n",
      "\t[1,   100] D loss: 0.000532845\n",
      "\t[1,   200] D loss: 0.000528908\n",
      "\t[2,   100] D loss: 0.000550152\n",
      "\t[2,   200] D loss: 0.000503704\n",
      "\t[3,   100] D loss: 0.000506600\n",
      "\t[3,   200] D loss: 0.000543027\n",
      "\t\t Running 83th iteration on G\n",
      "\t[3,   100] G loss: 0.000434534\n",
      "\t[3,   200] G loss: 0.000433893\n",
      "Currently running epoch Nbr 84\n",
      "\t[1,   100] D loss: 0.000493902\n",
      "\t[1,   200] D loss: 0.000580256\n",
      "\t[2,   100] D loss: 0.000525571\n",
      "\t[2,   200] D loss: 0.000522585\n",
      "\t[3,   100] D loss: 0.000529556\n",
      "\t[3,   200] D loss: 0.000515554\n",
      "\t\t Running 84th iteration on G\n",
      "\t[3,   100] G loss: 0.000426764\n",
      "\t[3,   200] G loss: 0.000426331\n",
      "Currently running epoch Nbr 85\n",
      "\t[1,   100] D loss: 0.000572586\n",
      "\t[1,   200] D loss: 0.000483199\n",
      "\t[2,   100] D loss: 0.000515837\n",
      "\t[2,   200] D loss: 0.000494280\n",
      "\t[3,   100] D loss: 0.000521781\n",
      "\t[3,   200] D loss: 0.000526822\n",
      "\t\t Running 85th iteration on G\n",
      "\t[3,   100] G loss: 0.000419676\n",
      "\t[3,   200] G loss: 0.000419260\n",
      "Currently running epoch Nbr 86\n",
      "\t[1,   100] D loss: 0.000530523\n",
      "\t[1,   200] D loss: 0.000505009\n",
      "\t[2,   100] D loss: 0.000529437\n",
      "\t[2,   200] D loss: 0.000513671\n",
      "\t[3,   100] D loss: 0.000511155\n",
      "\t[3,   200] D loss: 0.000523794\n",
      "\t\t Running 86th iteration on G\n",
      "\t[3,   100] G loss: 0.000412924\n",
      "\t[3,   200] G loss: 0.000412519\n",
      "Currently running epoch Nbr 87\n",
      "\t[1,   100] D loss: 0.000519839\n",
      "\t[1,   200] D loss: 0.000496920\n",
      "\t[2,   100] D loss: 0.000512689\n",
      "\t[2,   200] D loss: 0.000501438\n",
      "\t[3,   100] D loss: 0.000524218\n",
      "\t[3,   200] D loss: 0.000507084\n",
      "\t\t Running 87th iteration on G\n",
      "\t[3,   100] G loss: 0.000405761\n",
      "\t[3,   200] G loss: 0.000404783\n",
      "Currently running epoch Nbr 88\n",
      "\t[1,   100] D loss: 0.000477243\n",
      "\t[1,   200] D loss: 0.000532539\n",
      "\t[2,   100] D loss: 0.000491147\n",
      "\t[2,   200] D loss: 0.000521207\n",
      "\t[3,   100] D loss: 0.000481702\n",
      "\t[3,   200] D loss: 0.000501372\n",
      "\t\t Running 88th iteration on G\n",
      "\t[3,   100] G loss: 0.000398679\n",
      "\t[3,   200] G loss: 0.000398787\n",
      "Currently running epoch Nbr 89\n",
      "\t[1,   100] D loss: 0.000513299\n",
      "\t[1,   200] D loss: 0.000487285\n",
      "\t[2,   100] D loss: 0.000487210\n",
      "\t[2,   200] D loss: 0.000510625\n",
      "\t[3,   100] D loss: 0.000490597\n",
      "\t[3,   200] D loss: 0.000485877\n",
      "\t\t Running 89th iteration on G\n",
      "\t[3,   100] G loss: 0.000392284\n",
      "\t[3,   200] G loss: 0.000392342\n",
      "Currently running epoch Nbr 90\n",
      "\t[1,   100] D loss: 0.000480358\n",
      "\t[1,   200] D loss: 0.000483685\n",
      "\t[2,   100] D loss: 0.000463951\n",
      "\t[2,   200] D loss: 0.000446743\n",
      "\t[3,   100] D loss: 0.000488927\n",
      "\t[3,   200] D loss: 0.000452730\n",
      "\t\t Running 90th iteration on G\n",
      "\t[3,   100] G loss: 0.000385956\n",
      "\t[3,   200] G loss: 0.000386274\n",
      "Currently running epoch Nbr 91\n",
      "\t[1,   100] D loss: 0.000479655\n",
      "\t[1,   200] D loss: 0.000469707\n",
      "\t[2,   100] D loss: 0.000517003\n",
      "\t[2,   200] D loss: 0.000441314\n",
      "\t[3,   100] D loss: 0.000490459\n",
      "\t[3,   200] D loss: 0.000466271\n",
      "\t\t Running 91th iteration on G\n",
      "\t[3,   100] G loss: 0.000380595\n",
      "\t[3,   200] G loss: 0.000380197\n",
      "Currently running epoch Nbr 92\n",
      "\t[1,   100] D loss: 0.000475735\n",
      "\t[1,   200] D loss: 0.000468123\n",
      "\t[2,   100] D loss: 0.000479520\n",
      "\t[2,   200] D loss: 0.000451613\n",
      "\t[3,   100] D loss: 0.000465625\n",
      "\t[3,   200] D loss: 0.000450622\n",
      "\t\t Running 92th iteration on G\n",
      "\t[3,   100] G loss: 0.000374574\n",
      "\t[3,   200] G loss: 0.000374132\n",
      "Currently running epoch Nbr 93\n",
      "\t[1,   100] D loss: 0.000457381\n",
      "\t[1,   200] D loss: 0.000475615\n",
      "\t[2,   100] D loss: 0.000476170\n",
      "\t[2,   200] D loss: 0.000461793\n",
      "\t[3,   100] D loss: 0.000461417\n",
      "\t[3,   200] D loss: 0.000446870\n",
      "\t\t Running 93th iteration on G\n",
      "\t[3,   100] G loss: 0.000368337\n",
      "\t[3,   200] G loss: 0.000367748\n",
      "Currently running epoch Nbr 94\n",
      "\t[1,   100] D loss: 0.000448055\n",
      "\t[1,   200] D loss: 0.000449282\n",
      "\t[2,   100] D loss: 0.000472199\n",
      "\t[2,   200] D loss: 0.000457865\n",
      "\t[3,   100] D loss: 0.000414761\n",
      "\t[3,   200] D loss: 0.000463290\n",
      "\t\t Running 94th iteration on G\n",
      "\t[3,   100] G loss: 0.000362766\n",
      "\t[3,   200] G loss: 0.000362630\n",
      "Currently running epoch Nbr 95\n",
      "\t[1,   100] D loss: 0.000447584\n",
      "\t[1,   200] D loss: 0.000454537\n",
      "\t[2,   100] D loss: 0.000441599\n",
      "\t[2,   200] D loss: 0.000451439\n",
      "\t[3,   100] D loss: 0.000440226\n",
      "\t[3,   200] D loss: 0.000437142\n",
      "\t\t Running 95th iteration on G\n",
      "\t[3,   100] G loss: 0.000357217\n",
      "\t[3,   200] G loss: 0.000356799\n",
      "Currently running epoch Nbr 96\n",
      "\t[1,   100] D loss: 0.000446485\n",
      "\t[1,   200] D loss: 0.000460405\n",
      "\t[2,   100] D loss: 0.000421673\n",
      "\t[2,   200] D loss: 0.000450055\n",
      "\t[3,   100] D loss: 0.000450787\n",
      "\t[3,   200] D loss: 0.000428752\n",
      "\t\t Running 96th iteration on G\n",
      "\t[3,   100] G loss: 0.000352132\n",
      "\t[3,   200] G loss: 0.000351734\n",
      "Currently running epoch Nbr 97\n",
      "\t[1,   100] D loss: 0.000410637\n",
      "\t[1,   200] D loss: 0.000468400\n",
      "\t[2,   100] D loss: 0.000433439\n",
      "\t[2,   200] D loss: 0.000428210\n",
      "\t[3,   100] D loss: 0.000444687\n",
      "\t[3,   200] D loss: 0.000433972\n",
      "\t\t Running 97th iteration on G\n",
      "\t[3,   100] G loss: 0.000346960\n",
      "\t[3,   200] G loss: 0.000346784\n",
      "Currently running epoch Nbr 98\n",
      "\t[1,   100] D loss: 0.000409698\n",
      "\t[1,   200] D loss: 0.000445497\n",
      "\t[2,   100] D loss: 0.000416885\n",
      "\t[2,   200] D loss: 0.000450682\n",
      "\t[3,   100] D loss: 0.000424629\n",
      "\t[3,   200] D loss: 0.000412339\n",
      "\t\t Running 98th iteration on G\n",
      "\t[3,   100] G loss: 0.000341442\n",
      "\t[3,   200] G loss: 0.000341941\n",
      "Currently running epoch Nbr 99\n",
      "\t[1,   100] D loss: 0.000445698\n",
      "\t[1,   200] D loss: 0.000403329\n",
      "\t[2,   100] D loss: 0.000407469\n",
      "\t[2,   200] D loss: 0.000427353\n",
      "\t[3,   100] D loss: 0.000418899\n",
      "\t[3,   200] D loss: 0.000409958\n",
      "\t\t Running 99th iteration on G\n",
      "\t[3,   100] G loss: 0.000336513\n",
      "\t[3,   200] G loss: 0.000336586\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "G = generativeNet()\n",
    "D = discrimNet()\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "\n",
    "# Define a Loss function and optimizer\n",
    "optimizer1 = optim.SGD(D.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimizer2 = optim.SGD(G.parameters(), lr=0.0001, momentum=0.9)\n",
    "# k = discriminator interations\n",
    "k = 3\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "loss_g = []\n",
    "loss_d = []\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(100):\n",
    "    print(\"Currently running epoch Nbr %d\" % epoch)\n",
    "    \n",
    "    # train D for k iterations \n",
    "    for d in range(k):\n",
    "        #print(\"\\tRunning D iteration Nbr %d\" % d)\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer1.zero_grad()\n",
    "            # sample batch_size * 10 matrix of uniform distributed noise\n",
    "            noise = sample_noise(batch_size).to(device)\n",
    "            outputs_fake = D(G(noise).detach())\n",
    "            outputs_real = D(inputs)\n",
    "            loss = criterion(outputs_real, labels_real) + criterion(outputs_fake, labels_fake)\n",
    "            loss.backward()\n",
    "            optimizer1.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:   # print every 1000 mini-batches\n",
    "                print('\\t[%d, %5d] D loss: %.9f' %\n",
    "                      (d + 1, i + 1, running_loss / 99))\n",
    "                loss_d.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "\n",
    "    # 1 training step for G\n",
    "    print(\"\\t\\t Running %dth iteration on G\" % epoch)\n",
    "    running_loss = 0.0\n",
    "    for i in range(200):\n",
    "        optimizer2.zero_grad()\n",
    "        noise = sample_noise(batch_size).to(device)\n",
    "        loss = criterion(D(G(noise)), labels_fake)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:   # print every 1000 mini-batches\n",
    "                print('\\t[%d, %5d] G loss: %.9f' %\n",
    "                      (d + 1, i + 1, running_loss / 99))\n",
    "                loss_g.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(loss_g, loss_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4167e-04, 9.9966e-01]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[1.0000e+00, 3.5059e-06]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = sample_noise(1).cuda()\n",
    "\n",
    "a = G(s)\n",
    "\n",
    "a = torch.reshape(G(s), (28,28)).cpu()\n",
    "img = torchvision.utils.make_grid(a)\n",
    "\n",
    "img = img / 2 + 0.5     # unnormalize\n",
    "npimg = img.detach().numpy()\n",
    "#plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.imshow(np.transpose(a.detach().numpy(), (0, 1)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(D(G(s).detach()))\n",
    "\n",
    "\n",
    "trainloader, validation_loader, test_loader = load_mnist_minibatched(batch_size)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(D(images[0].to(device)))\n",
    "\n",
    "img = torchvision.utils.make_grid(images[0])\n",
    "\n",
    "#img = img / 2 + 0.5\n",
    "npimg = img.numpy()\n",
    "plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
